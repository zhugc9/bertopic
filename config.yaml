# BERTopic议题分析系统配置文件
# =====================================
# 用于配置媒体文本和社交媒体文本的主题建模分析参数

# ========== 数据文件路径 ==========
data_paths:
  media_data: "data/媒体_最终分析数据库.xlsx"      # 传统媒体数据文件路径
  social_media_data: "data/社交媒体_最终分析数据库.xlsx"  # 社交媒体数据文件路径

# ========== 结果输出路径 ==========
results_paths:
  output_dir: "results"                              # 主输出目录
  model_dir: "results/trained_model"                 # 训练好的模型保存路径
  summary_file: "results/topics_summary.csv"         # 主题摘要CSV文件
  summary_enhanced: "results/topics_summary_enhanced.csv"  # 增强主题摘要
  cross_lingual_file: "results/cross_lingual_composition.csv"  # 跨语言分析
  evolution_file: "results/dynamic_evolution_analysis.csv"     # 动态演化分析
  viz_file: "results/topic_visualization.html"       # 主题可视化HTML文件
  source_analysis: "results/topic_by_source.html"    # 按来源分析结果
  timeline_analysis: "results/topics_over_time.html" # 时间序列分析结果
  frame_heatmap: "results/topic_frame_heatmap.html"  # 框架热力图
  # 学术级图表输出路径
  academic_charts:
    topic_distribution: "results/academic_topic_distribution.png"  # 主题分布图
    topic_sizes: "results/academic_topic_sizes.png"               # 主题规模图
    topic_evolution: "results/academic_topic_evolution.png"       # 主题演化图
    cross_lingual: "results/academic_cross_lingual.png"           # 跨语言分析图

# ========== 数据处理参数 ==========
data_processing:
  text_column: "Unit_Text"   # 用于主题建模的文本列名（优先使用Unit_Text）
  merge_strategy: "concat"   # 数据合并方式: concat(拼接)/inner(交集)/outer(并集)
  
  # 保留用于后续分析的元数据列（兼容两种数据格式）
  metadata_columns:
    # 基础信息列
    - "序号"                                      # 序号
    - "日期"                                      # 时间信息
    - "标题"                                      # 标题
    - "链接"                                      # 链接（可能存在）
    - "Token数"                                   # Token计数
    - "text"                                      # 原始文本
    - "token数"                                   # token计数
    - "Unit_ID"                                   # 单元ID
    - "Source"                                    # 数据来源
    - "Macro_Chunk_ID"                           # 宏块ID
    - "speaker"                                   # 发言者
    - "Unit_Text"                                # 单元文本
    - "seed_sentence"                            # 种子句子
    - "expansion_logic"                          # 扩展逻辑
    - "Unit_Hash"                                # 单元哈希
    - "processing_status"                        # 处理状态
    - "Incident"                                 # 事件
    - "Valence"                                  # 情感倾向
    
    # Frame分析列（两种格式）
    - "Frame_ProblemDefinition"                  # 问题定义框架
    - "Frame_ProblemDefinition_Present"          # 问题定义框架（Present格式）
    - "Frame_ResponsibilityAttribution"          # 责任归因框架
    - "Frame_ResponsibilityAttribution_Present"  # 责任归因框架（Present格式）
    - "Frame_MoralEvaluation"                    # 道德评价框架
    - "Frame_MoralEvaluation_Present"            # 道德评价框架（Present格式）
    - "Frame_SolutionRecommendation"             # 解决方案推荐框架
    - "Frame_TreatmentRecommendation_Present"    # 治疗建议框架（Present格式）
    - "Frame_ActionStatement"                    # 行动声明框架
    - "Frame_ConflictAttribution_Present"        # 冲突归因框架（Present格式）
    - "Frame_CausalExplanation"                  # 因果解释框架
    - "Frame_CausalInterpretation_Present"       # 因果解释框架（Present格式）
    - "Frame_HumanInterest_Present"              # 人文关怀框架（Present格式）
    - "Frame_EconomicConsequences_Present"       # 经济后果框架（Present格式）
    
    # 分析维度列
    - "Evidence_Type"                            # 证据类型
    - "Attribution_Level"                        # 归因级别
    - "Temporal_Focus"                           # 时间焦点
    - "Primary_Actor_Type"                       # 主要参与者类型
    - "Geographic_Scope"                         # 地理范围
    - "Relationship_Model_Definition"            # 关系模型定义
    - "Discourse_Type"                           # 话语类型

# ========== BERTopic模型核心参数 ==========
bertopic_params:
  # 文本嵌入模型配置
  language: "multilingual"  # 语言设置: 支持中英文混合文本
  embedding_model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"  # 多语言嵌入模型
  
  # 主题建模核心参数
  min_topic_size: 15        # 最小主题大小: 少于15个文档的主题将被合并
  nr_topics: "auto"         # 主题数量: auto(自动)/具体数字(如20)
  n_gram_range: [1, 3]      # 词汇组合范围: 1-3个词的组合
  
  # ========== 专家级关键词提取参数 ==========
  expert_keyword_extraction:
    enable_pos_patterns: true           # 启用词性标注模式
    pos_patterns:                       # 基于词性的短语模式
      zh: '<n.*|a.*>*<n.*>+'           # 中文: (名词|形容词)*名词+
      en: '<JJ.*>*<NN.*>+'             # 英文: 形容词*名词+
      ru: '<A.*>*<N.*>+'               # 俄文: 形容词*名词+
    custom_stopwords_path: "stopwords/politics_stopwords.txt"  # 自定义停用词表路径
    use_custom_stopwords: true          # 启用自定义停用词
    pos_language_detection: true        # 自动语言检测
  
  # UMAP降维参数 (影响主题分离度)
  umap_params:
    n_neighbors: 15         # 邻居数量: 影响局部vs全局结构平衡
    n_components: 5         # 降维后维度: 通常2-5维
    min_dist: 0.0           # 最小距离: 0.0=紧密聚类, 1.0=松散聚类
    metric: "cosine"        # 距离度量: cosine适合文本相似度
    random_state: 42        # 随机种子: 确保结果可重现
  
  # HDBSCAN聚类参数 (影响主题形成)
  hdbscan_params:
    min_cluster_size: 15    # 最小聚类大小: 与min_topic_size保持一致
    min_samples: 5          # 最小样本数: 影响聚类稳定性
    metric: "euclidean"     # 聚类距离度量
    cluster_selection_method: "eom"  # 聚类选择方法: eom(基于密度)
    prediction_data: true   # 保存预测数据: 用于新文档分类

# ========== 可视化参数 ==========
visualization:
  figsize: [12, 8]          # 图表尺寸 [宽, 高]
  dpi: 100                  # 图像分辨率
  style: "plotly"           # 可视化库: plotly(交互式)/matplotlib(静态)
  color_scheme: "viridis"   # 配色方案: viridis/plasma/inferno等
  save_format: "html"       # 保存格式: html(交互式)/png(静态)/svg(矢量)

# ========== 高级分析功能 ==========
analysis:
  # 时间序列分析: 观察主题随时间变化
  time_analysis:
    enable: true            # 是否启用时间分析
    time_column: "日期"     # 时间列名
    bins: 10                # 时间段划分数量: 将时间轴分为10个区间
    
  # 来源对比分析: 比较不同媒体来源的主题差异
  source_analysis:
    enable: true            # 是否启用来源分析
    source_column: "Source" # 来源列名
    
  # 框架交叉分析: 分析主题与新闻框架的关系
  frame_analysis:
    enable: true            # 是否启用框架分析
    threshold: 0.1          # 框架出现频率阈值: 低于10%的框架将被忽略

# ========== 系统运行参数 ==========
system:
  random_seed: 42           # 随机种子: 确保结果可重现
  verbose: true             # 详细输出: 显示处理进度和中间结果
  save_intermediate: false  # 保存中间结果: 调试时可设为true
  use_gpu: false            # GPU加速: 有GPU时可设为true提升速度