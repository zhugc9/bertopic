#!/usr/bin/env python3
"""
BERTopicä¸»é¢˜æ ‡ç­¾ç”Ÿæˆå™¨ - ç®€æ´å®ç°
===============================
è‡ªåŠ¨ä¸ºBERTopicä¸»é¢˜ç”Ÿæˆä¸­æ–‡æ ‡ç­¾
"""

# =============================================================================
# ğŸ”§ ç”¨æˆ·é…ç½®åŒºåŸŸ - è¯·æ ¹æ®éœ€è¦ä¿®æ”¹ä»¥ä¸‹é…ç½®
# =============================================================================

# APIé…ç½®
API_KEY = "sk-oS1mPWSBCvf5czQQ1CyRXRGWOWQ4CFWis8qNV0UlEqbQYzoH"  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„APIå¯†é’¥
API_URL = "https://openai.sharkmagic.com.cn/v1/chat/completions"  # APIä»£ç†åœ°å€
MODEL_NAME = "[å®˜è‡ª-0.7]gemini-2-5-flash"  # ä½¿ç”¨çš„æ¨¡å‹

# æç¤ºè¯é…ç½®
PROMPT_TEMPLATE = """åŸºäºå…³é”®è¯ç”Ÿæˆä¸­æ–‡è®®é¢˜åç§°ï¼Œè¦æ±‚10-15ä¸ªæ±‰å­—ï¼Œè¾“å‡ºJSONæ ¼å¼ï¼š
å…³é”®è¯ï¼š{keywords}
è¾“å‡ºï¼š{{"topic_label": "è®®é¢˜åç§°"}}"""

# å¤„ç†é…ç½®
MAX_RETRIES = 3  # APIè°ƒç”¨æœ€å¤§é‡è¯•æ¬¡æ•°
REQUEST_DELAY = 0.5  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
TIMEOUT = 60  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# æ–‡ä»¶è·¯å¾„é…ç½®ï¼ˆåŸºäºè„šæœ¬ä½ç½®ï¼‰
SCRIPT_DIR = Path(__file__).parent
INPUT_FILE = SCRIPT_DIR / "results/topics_summary.csv"  # è¾“å…¥æ–‡ä»¶è·¯å¾„
OUTPUT_FILE = SCRIPT_DIR / "results/topics_summary_labeled.csv"  # è¾“å‡ºæ–‡ä»¶è·¯å¾„

# =============================================================================
# ğŸ“¦ å¯¼å…¥ä¾èµ–åº“
# =============================================================================

import os
import sys
import yaml
import json
import requests
import pandas as pd
from tqdm import tqdm
import time


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = SCRIPT_DIR / "config.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def load_topics_summary(file_path) -> pd.DataFrame:
    """åŠ è½½ä¸»é¢˜æ‘˜è¦CSVæ–‡ä»¶"""
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        print("è¯·å…ˆè¿è¡Œ main.py ç”Ÿæˆ topics_summary.csv æ–‡ä»¶")
        sys.exit(1)
    
    df = pd.read_csv(file_path, encoding='utf-8')
    print(f"âœ… åŠ è½½ {len(df)} ä¸ªä¸»é¢˜")
    return df


def build_prompt(keywords: str) -> str:
    """æ„å»ºAPIè¯·æ±‚çš„æç¤ºè¯"""
    return PROMPT_TEMPLATE.format(keywords=keywords)


def call_llm_api(prompt: str, api_key: str) -> str:
    """è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹API - å‚è€ƒç¤¾åª’è¯„è®ºé¡¹ç›®"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    data = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0,
        "response_format": {"type": "json_object"}
    }
    
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(
                API_URL,
                headers=headers,
                json=data,
                timeout=TIMEOUT
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                
                # è§£æJSON
                try:
                    json_result = json.loads(content)
                    return json_result.get('topic_label', '')
                except:
                    # æå–ä¸­æ–‡æ–‡æœ¬
                    import re
                    chinese_match = re.search(r'[\u4e00-\u9fff]+', content)
                    return chinese_match.group(0) if chinese_match else content
            else:
                if attempt < MAX_RETRIES - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
                return f"[APIé”™è¯¯: {response.status_code}]"
        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                continue
            return f"[APIè°ƒç”¨å¤±è´¥: {str(e)[:50]}]"
    
    return "[APIè°ƒç”¨å¤±è´¥: è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°]"


def process_topics(df: pd.DataFrame, api_key: str) -> pd.DataFrame:
    """ä¸ºæ‰€æœ‰ä¸»é¢˜ç”Ÿæˆæ ‡ç­¾"""
    print("ğŸ¤– å¼€å§‹ç”Ÿæˆä¸»é¢˜æ ‡ç­¾...")
    
    df['AI_Generated_Label'] = ''
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="ç”Ÿæˆæ ‡ç­¾"):
        keywords = row['Top_Words']
        prompt = build_prompt(keywords)
        label = call_llm_api(prompt, api_key)
        df.at[idx, 'AI_Generated_Label'] = label
        time.sleep(REQUEST_DELAY)  # é¿å…APIé™åˆ¶
    
    return df


def save_results(df: pd.DataFrame, output_path):
    """ä¿å­˜ç»“æœ"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(output_path, index=False, encoding='utf-8')
    print(f"âœ… ç»“æœå·²ä¿å­˜: {output_path}")


def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    print("="*50)
    print("ğŸ·ï¸  BERTopicä¸»é¢˜æ ‡ç­¾ç”Ÿæˆå™¨")
    print("="*50)
    
    # åŠ è½½é…ç½®
    config = load_config()
    
    # åŠ è½½æ•°æ®
    input_file = SCRIPT_DIR / config['results_paths']['summary_file']
    df = load_topics_summary(input_file)
    
    # ç”Ÿæˆæ ‡ç­¾
    df_labeled = process_topics(df, API_KEY)
    
    # ä¿å­˜ç»“æœ
    save_results(df_labeled, OUTPUT_FILE)
    
    print("\nâœ¨ å®Œæˆï¼")
    print(f"ğŸ“Š å¤„ç†äº† {len(df)} ä¸ªä¸»é¢˜")
    print(f"ğŸ“ ç»“æœ: {OUTPUT_FILE}")
    print("="*50)


if __name__ == "__main__":
    main()
