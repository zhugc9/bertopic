#!/usr/bin/env python3
"""
BERTopicä¸»é¢˜åˆ†æç³»ç»Ÿ - ç»Ÿä¸€å…¥å£
===============================
é›†æˆè¶…å‚æ•°ä¼˜åŒ–ã€å¤šè¯­è¨€é¢„å¤„ç†ã€é«˜çº§å¯è§†åŒ–çš„å®Œæ•´åˆ†ææµç¨‹
"""

import os
import sys
import yaml
import logging
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Any
from tools.workflow_manager import WorkflowManager

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™BERTopicWorkflowåˆ«å
BERTopicWorkflow = WorkflowManager


def main():
    """ä¸»èœå•ç•Œé¢"""
    print("ğŸ“ BERTopicä¸»é¢˜åˆ†æç³»ç»Ÿ")
    print("=" * 50)
    print("ğŸ’¡ æ¨èå·¥ä½œæµç¨‹ï¼š")
    print("1. ä¿®æ”¹ config.yaml è®¾ç½®æ‚¨çš„å‚æ•°")
    print("2. è¿è¡Œ python main.py --run")
    print("3. æŸ¥çœ‹ results/ æ–‡ä»¶å¤¹è·å–ç»“æœ")
    print("=" * 50)
    
    show_menu()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        return config
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = self.results_dir / 'bertopic_analysis.log'
        self.results_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger(__name__)
    
    def load_data(self) -> bool:
        """åŠ è½½æ•°æ®"""
        self.logger.info("ğŸ“ å¼€å§‹åŠ è½½æ•°æ®...")
        
        try:
            from topic_analyzer.data_loader import DataLoader
            
            self.data_loader = DataLoader(self.config)
            self.documents, self.metadata_df = self.data_loader.load_and_prepare_data()
            
            self.logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼š{len(self.documents)} ä¸ªæ–‡æ¡£")
            
            if self.metadata_df is not None:
                self.logger.info(f"  å…ƒæ•°æ®ç»´åº¦: {self.metadata_df.shape}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def run_hyperparameter_optimization(self) -> Optional[Dict]:
        """è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–"""
        opt_config = self.config.get('hyperparameter_optimization', {})
        
        if not opt_config.get('enable', False):
            self.logger.info("â­ï¸ è¶…å‚æ•°ä¼˜åŒ–å·²ç¦ç”¨ï¼Œè·³è¿‡")
            return None
        
        if not self.analyzer:
            from topic_analyzer.model import TopicAnalyzer
            self.analyzer = TopicAnalyzer(self.config)
        
        self.logger.info("ğŸ” å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–...")
        
        try:
            optimization_results = self.analyzer.optimize_hyperparameters(self.documents)
            
            if optimization_results:
                self.logger.info("âœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ")
                return optimization_results
            else:
                self.logger.warning("âš ï¸ è¶…å‚æ•°ä¼˜åŒ–æœªè¿”å›ç»“æœ")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return None
    
    def train_topic_model(self, use_optimized_params: bool = False) -> bool:
        """è®­ç»ƒä¸»é¢˜æ¨¡å‹"""
        if not self.analyzer:
            from topic_analyzer.model import TopicAnalyzer
            self.analyzer = TopicAnalyzer(self.config)
        
        self.logger.info("ğŸ¤– å¼€å§‹è®­ç»ƒä¸»é¢˜æ¨¡å‹...")
        
        try:
            if use_optimized_params:
                self.topic_model, self.topics = self.analyzer.train_with_optimized_parameters(self.documents)
                self.logger.info("  ä½¿ç”¨ä¼˜åŒ–å‚æ•°è®­ç»ƒ")
            else:
                self.topic_model, self.topics = self.analyzer.train_bertopic_model(self.documents)
                self.logger.info("  ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ")
            
            # æ¨¡å‹ç»Ÿè®¡
            topic_info = self.topic_model.get_topic_info()
            n_topics = len(topic_info) - 1  # æ’é™¤å™ªå£°ä¸»é¢˜
            
            self.logger.info(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
            self.logger.info(f"  å‘ç°ä¸»é¢˜æ•°: {n_topics}")
            self.logger.info(f"  æ€»æ–‡æ¡£æ•°: {len(self.documents)}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def generate_results(self) -> bool:
        """ç”Ÿæˆåˆ†æç»“æœ"""
        if not self.topic_model:
            self.logger.error("æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•ç”Ÿæˆç»“æœ")
            return False
        
        self.logger.info("ğŸ“Š ç”Ÿæˆåˆ†æç»“æœ...")
        
        try:
            # 1. åŸºç¡€ç»“æœ
            self.logger.info("  ç”ŸæˆåŸºç¡€ç»“æœ...")
            self.analyzer.generate_results(
                self.topic_model, 
                self.documents, 
                self.topics, 
                self.metadata_df
            )
            
            # 2. é«˜çº§å¯è§†åŒ–
            viz_config = self.config.get('visualization', {}).get('sota_charts', {})
            if viz_config.get('enable', True):
                self.logger.info("  ç”Ÿæˆé«˜çº§å¯è§†åŒ–...")
                charts = self.analyzer.generate_sota_visualizations(
                    self.topic_model,
                    self.documents, 
                    self.topics,
                    self.metadata_df
                )
                
                if charts:
                    self.logger.info(f"  âœ“ ç”Ÿæˆå›¾è¡¨: {len(charts)} ä¸ª")
                else:
                    self.logger.warning("  âš  å›¾è¡¨ç”Ÿæˆå¤±è´¥")
            else:
                self.logger.info("  â­ï¸ é«˜çº§å¯è§†åŒ–å·²ç¦ç”¨")
            
            self.logger.info("âœ… åˆ†æç»“æœç”Ÿæˆå®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ç»“æœç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def run_complete_analysis(self, optimize_params: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹å®Œæ•´ä¸»é¢˜åˆ†ææµç¨‹...")
        
        # 1. åŠ è½½æ•°æ®
        if not self.load_data():
            return False
        
        # 2. è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
        optimization_results = None
        if optimize_params:
            optimization_results = self.run_hyperparameter_optimization()
        
        # 3. è®­ç»ƒæ¨¡å‹
        use_optimized = optimization_results is not None
        if not self.train_topic_model(use_optimized_params=use_optimized):
            return False
        
        # 4. ç”Ÿæˆç»“æœ
        if not self.generate_results():
            return False
        
        self.logger.info("ğŸ‰ å®Œæ•´åˆ†ææµç¨‹æˆåŠŸå®Œæˆï¼")
        return True


def check_python_version() -> bool:
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    version = sys.version_info
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        print(f"   å½“å‰ç‰ˆæœ¬: {sys.version}")
        return False
    print(f"âœ… Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
    return True


def check_dependencies() -> bool:
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    required_packages = [
        'bertopic', 'pandas', 'numpy', 'sentence_transformers',
        'umap', 'hdbscan', 'plotly', 'yaml', 'streamlit'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…:")
        for pkg in missing_packages:
            print(f"   - {pkg}")
        print("\nğŸ“¦ è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True


def validate_config(config_path: Path = None) -> bool:
    """éªŒè¯é…ç½®æ–‡ä»¶"""
    if config_path is None:
        config_path = Path(__file__).parent / "config.yaml"
    
    if not config_path.exists():
        print("âŒ æœªæ‰¾åˆ°config.yamlé…ç½®æ–‡ä»¶")
        return False
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # åŸºæœ¬ç»“æ„éªŒè¯ - é€‚é…æ–°çš„ç”¨æˆ·å‹å¥½é…ç½®æ ¼å¼
        required_sections = ['topic_parameters', 'output_settings']
        for section in required_sections:
            if section not in config:
                print(f"âŒ é…ç½®ç¼ºå°‘å¿…éœ€çš„[{section}]éƒ¨åˆ†")
                return False
        
        print("âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
        return False


def check_data_files() -> bool:
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    try:
        # ä»config.yamlè¯»å–æ•°æ®è·¯å¾„
        config_path = Path(__file__).parent / "config.yaml"
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # æ£€æŸ¥é…ç½®çš„æ•°æ®è·¯å¾„
        data_paths = config.get('data_paths', {})
        media_data = data_paths.get('media_data')
        social_data = data_paths.get('social_media_data')
        
        found_files = 0
        if media_data and media_data != "null" and Path(media_data).exists():
            found_files += 1
            print(f"âœ… æ‰¾åˆ°ä¼ ç»Ÿåª’ä½“æ•°æ®: {media_data}")
            
        if social_data and social_data != "null" and Path(social_data).exists():
            found_files += 1
            print(f"âœ… æ‰¾åˆ°ç¤¾äº¤åª’ä½“æ•°æ®: {social_data}")
        
        if found_files == 0:
            print("âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
            print("   è¯·åœ¨config.yamlä¸­æ­£ç¡®é…ç½®data_paths")
            return False
        
        print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {found_files} ä¸ª")
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        return False


def run_analysis():
    """è¿è¡Œä¸»é¢˜åˆ†æ"""
    print("\n" + "="*60)
    print("ğŸš€ å¼€å§‹BERTopicä¸»é¢˜åˆ†æ...")
    print("="*60 + "\n")
    
    try:
        # å¯¼å…¥åˆ†ææ¨¡å—
        sys.path.append(str(Path(__file__).parent))
        from topic_analyzer.data_loader import DataLoader
        from topic_analyzer.model import TopicAnalyzer
        from config_manager import ConfigManager
        
        # é…ç½®æ—¥å¿—
        log_file = Path(__file__).parent / 'analysis.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        
        # åŠ è½½é…ç½®
        config_path = Path(__file__).parent / "config.yaml"
        config_manager = ConfigManager(config_path)
        config = config_manager.get_config()
        
        # åŠ è½½æ•°æ®
        print("ğŸ“ åŠ è½½æ•°æ®...")
        loader = DataLoader(config)
        documents, metadata_df = loader.load_and_prepare_data()
        print(f"âœ… å·²åŠ è½½ {len(documents)} æ¡æ–‡æ¡£")
        
        # è®­ç»ƒæ¨¡å‹
        print("ğŸ¤– è®­ç»ƒä¸»é¢˜æ¨¡å‹...")
        analyzer = TopicAnalyzer(config)
        topic_model, topics = analyzer.train_bertopic_model(documents)
        
        # ç”Ÿæˆç»“æœ
        print("ğŸ“Š ç”Ÿæˆåˆ†æç»“æœ...")
        results_dir = Path(config['results_paths']['output_dir'])
        results_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆå®Œæ•´ç»“æœï¼ˆåŒ…å«SOTAå¯è§†åŒ–ï¼‰
        analyzer.generate_results(topic_model, documents, topics, metadata_df)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨SOTAå¯è§†åŒ–
        sota_config = config.get('visualization', {}).get('sota_charts', {})
        if sota_config.get('enable', True):
            print("ğŸ¨ ç”ŸæˆSOTAçº§å¯è§†åŒ–...")
            sota_charts = analyzer.generate_sota_visualizations(
                topic_model, documents, topics, metadata_df
            )
            if sota_charts:
                print(f"âœ… ç”ŸæˆSOTAå›¾è¡¨: {len(sota_charts)} ä¸ª")
        
        # åŸºç¡€ç»Ÿè®¡
        topic_info = topic_model.get_topic_info()
        n_topics = len(topic_info) - 1  # -1æ’é™¤å™ªå£°ä¸»é¢˜
        
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {results_dir}")
        print(f"ğŸ“Š å‘ç°ä¸»é¢˜æ•°: {n_topics}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        logging.error(f"Analysis failed: {e}")
        return False


def show_menu():
    """æ˜¾ç¤ºä¸»èœå•"""
    print("\nğŸš€ BERTopicä¸»é¢˜åˆ†æç³»ç»Ÿ")
    print("="*50)
    print("ğŸ’¡ æç¤ºï¼šæ‰€æœ‰åˆ†æå‚æ•°é€šè¿‡ config.yaml æ–‡ä»¶æ§åˆ¶")
    print("-"*50)
    print("1. å¼€å§‹ä¸»é¢˜åˆ†æ (æ¨è)")
    print("2. å¯åŠ¨Webç•Œé¢")
    print("3. æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ")
    print("4. é€€å‡º")
    print("="*50)
    print("ğŸ“ ä½¿ç”¨è¯´æ˜ï¼š")
    print("   - ä¿®æ”¹ config.yaml è®¾ç½®åˆ†æå‚æ•°")
    print("   - é€‰æ‹©1å¼€å§‹åˆ†æï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯»å–æ‚¨çš„é…ç½®")
    print("="*50)


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ” BERTopicä¸»é¢˜åˆ†æç³»ç»Ÿ - ç¯å¢ƒæ£€æŸ¥")
    print("="*60)
    
    # ç¯å¢ƒæ£€æŸ¥
    checks = [
        ("Pythonç‰ˆæœ¬", check_python_version),
        ("ä¾èµ–åŒ…", check_dependencies),
        ("é…ç½®æ–‡ä»¶", validate_config),
        ("æ•°æ®æ–‡ä»¶", check_data_files),
    ]
    
    all_passed = True
    for check_name, check_func in checks:
        print(f"\nğŸ” æ£€æŸ¥{check_name}...")
        if not check_func():
            all_passed = False
    
    if not all_passed:
        print("\n" + "="*60)
        print("âš ï¸ è¯·å…ˆè§£å†³ä¸Šè¿°é—®é¢˜åå†è¿è¡Œ")
        print("="*60)
        return
    
    print("\n" + "="*60)
    print("âœ¨ ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼")
    print("="*60)
    
    # æ˜¾ç¤ºèœå•
    while True:
        show_menu()
        try:
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-4): ").strip()
            
            if choice == '1':
                # åŸºäºconfig.yamlçš„æ™ºèƒ½åˆ†æ
                print("\nğŸ¯ æ­£åœ¨è¯»å– config.yaml é…ç½®...")
                if run_user_friendly_analysis():
                    break
                    
            elif choice == '2':
                print("\nğŸŒ å¯åŠ¨Webç•Œé¢...")
                print("è¯·è¿è¡Œ: streamlit run web_ui.py --server.port 8502")
                print("æˆ–åŒå‡»: run_web.bat")
                break
                
            elif choice == '3':
                print("\nâœ… ç¯å¢ƒæ£€æŸ¥å·²å®Œæˆï¼Œå¯ä»¥è¿›è¡Œåˆ†æ")
                break
                
            elif choice == '4':
                print("\nğŸ‘‹ å†è§ï¼")
                break
                
            else:
                print("\nâŒ è¯·è¾“å…¥1-4ä¹‹é—´çš„æ•°å­—")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")


def run_user_friendly_analysis() -> bool:
    """
    è¿è¡Œç”¨æˆ·å‹å¥½çš„åˆ†æï¼ˆåŸºäºconfig.yamlç”¨æˆ·é…ç½®ï¼‰
    """
    try:
        config_path = Path(__file__).parent / "config.yaml"
        
        # ä½¿ç”¨é…ç½®ç¿»è¯‘å™¨è½¬æ¢ç”¨æˆ·é…ç½®
        from tools.config_translator import ConfigTranslator
        translator = ConfigTranslator(str(config_path))
        analysis_mode = translator.get_analysis_mode()
        
        print(f"\nğŸ¯ æ£€æµ‹åˆ°è¿è¡Œæ¨¡å¼: {analysis_mode}")
        
        if analysis_mode == 'tune':
            # ç¬¬ä¸€é˜¶æ®µï¼šæœºå™¨è°ƒå‚
            return run_tuning_phase(translator)
        else:
            # ç¬¬äºŒé˜¶æ®µï¼šæ­£å¼åˆ†æ
            return run_analysis_phase(translator)
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_tuning_phase(translator) -> bool:
    """
    è¿è¡Œç¬¬ä¸€é˜¶æ®µï¼šæœºå™¨è°ƒå‚
    
    Args:
        translator: é…ç½®ç¿»è¯‘å™¨
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print("\nğŸ” ç¬¬ä¸€é˜¶æ®µï¼šæœºå™¨è‡ªåŠ¨è°ƒå‚ (æµ·é€‰æ¨¡å¼)")
    print("=" * 50)
    print("ğŸ’¡ æœºå™¨å°†å°è¯•æ•°ç™¾ç§å‚æ•°ç»„åˆï¼Œä¸ºæ‚¨ç­›é€‰å‡ºTop 5æœ€ä½³å€™é€‰")
    print("â° é¢„è®¡è€—æ—¶ï¼š30-60åˆ†é’Ÿï¼ˆå–å†³äºæ•°æ®é‡å’Œè¯•éªŒæ¬¡æ•°ï¼‰")
    print("â˜• æ‚¨å¯ä»¥å»å–æ¯å’–å•¡ï¼Œæœºå™¨ä¼šä¸çŸ¥ç–²å€¦åœ°å·¥ä½œ...")
    
    try:
        # è½¬æ¢æŠ€æœ¯é…ç½®
        tech_config = translator.translate_to_technical_config()
        temp_config_path = Path("temp_tuning_config.yaml")
        translator.save_technical_config(str(temp_config_path))
        
        # è¿è¡Œè°ƒå‚å·¥ä½œæµ
        workflow = BERTopicWorkflow(str(temp_config_path))
        
        # åªè¿è¡Œè¶…å‚æ•°ä¼˜åŒ–
        loaded_data = workflow.load_data()
        if loaded_data:
            optimization_results = workflow.run_hyperparameter_optimization()
            if optimization_results:
                # ä¿å­˜è°ƒå‚ç»“æœ
                from tools.tuning_manager import save_tuning_results
                save_tuning_results(str(translator.config_path), optimization_results)
                success = True
            else:
                success = False
        else:
            success = False
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_config_path.exists():
            temp_config_path.unlink()
        
        if success:
            print("\nğŸ‰ ç¬¬ä¸€é˜¶æ®µè°ƒå‚å®Œæˆï¼")
            print("ğŸ“‹ æœºå™¨å·²ä¸ºæ‚¨ç­›é€‰å‡ºTop 5æœ€ä½³å‚æ•°ç»„åˆ")
            print("\nğŸ”„ ä¸‹ä¸€æ­¥æ“ä½œï¼š")
            print("1. æŸ¥çœ‹ results/å€™é€‰å‚æ•°é€‰æ‹©æŒ‡å—.txt")
            print("2. åœ¨config.yamlä¸­è®¾ç½® selected_candidate: X (1-5)")
            print("3. å°† mode æ”¹ä¸º 'analyze' å¹¶é‡æ–°è¿è¡Œ")
            print("4. å¯¹æ¯”ä¸åŒå€™é€‰å‚æ•°çš„åˆ†æç»“æœ")
        else:
            print("\nâŒ è°ƒå‚å¤±è´¥")
            
        return success
        
    except Exception as e:
        print(f"\nâŒ è°ƒå‚é˜¶æ®µå¤±è´¥: {e}")
        return False


def run_analysis_phase(translator) -> bool:
    """
    è¿è¡Œç¬¬äºŒé˜¶æ®µï¼šæ­£å¼åˆ†æ
    
    Args:
        translator: é…ç½®ç¿»è¯‘å™¨
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print("\nğŸ“Š ç¬¬äºŒé˜¶æ®µï¼šæ­£å¼åˆ†æ (æ·±åº¦æ¨¡å¼)")
    print("=" * 50)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰å‚æ•°
    candidate_config = translator.user_config.get('candidate_parameters', {})
    selected_candidate = candidate_config.get('selected_candidate', 1)
    
    if f'candidate_{selected_candidate}' in candidate_config:
        print(f"ğŸ¯ ä½¿ç”¨å€™é€‰å‚æ•° {selected_candidate}")
        candidate = candidate_config[f'candidate_{selected_candidate}']
        print(f"ğŸ“‹ å‚æ•°ç‰¹å¾: {candidate.get('description', 'æœªçŸ¥')}")
        print(f"ğŸ“ˆ ä¸€è‡´æ€§åˆ†æ•°: {candidate.get('coherence_score', 'N/A')}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°å€™é€‰å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    try:
        # è½¬æ¢æŠ€æœ¯é…ç½®
        tech_config = translator.translate_to_technical_config()
        temp_config_path = Path("temp_analysis_config.yaml")
        translator.save_technical_config(str(temp_config_path))
        
        # è¿è¡Œå®Œæ•´åˆ†æå·¥ä½œæµ
        workflow = BERTopicWorkflow(str(temp_config_path))
        success = workflow.run_complete_analysis(optimize_params=False)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_config_path.exists():
            temp_config_path.unlink()
        
        if success:
            print(f"\nğŸ‰ ç¬¬äºŒé˜¶æ®µåˆ†æå®Œæˆï¼")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {workflow.results_dir}")
            
            # ç”Ÿæˆç”¨æˆ·å‹å¥½çš„ç»“æœæ‘˜è¦
            generate_analysis_summary(workflow.results_dir, translator.user_config, selected_candidate)
            
            # å¦‚æœæ˜¯å€™é€‰å‚æ•°ï¼Œæç¤ºå¯¹æ¯”å…¶ä»–å€™é€‰
            if f'candidate_{selected_candidate}' in candidate_config:
                print(f"\nğŸ’¡ å»ºè®®ï¼š")
                print(f"â€¢ å·²å®Œæˆå€™é€‰ {selected_candidate} çš„åˆ†æ")
                print(f"â€¢ å¯å°è¯•å…¶ä»–å€™é€‰å‚æ•° (1-5) è¿›è¡Œå¯¹æ¯”")
                print(f"â€¢ æœ€ç»ˆé€‰æ‹©æœ€ç¬¦åˆæ‚¨ç ”ç©¶éœ€æ±‚çš„å‚æ•°ç»„åˆ")
        else:
            print(f"\nâŒ åˆ†æå¤±è´¥")
            
        return success
        
    except Exception as e:
        print(f"\nâŒ åˆ†æé˜¶æ®µå¤±è´¥: {e}")
        return False


def generate_user_summary(results_dir: Path, mode: str, user_config: dict):
    """
    ç”Ÿæˆç”¨æˆ·å‹å¥½çš„ç»“æœæ‘˜è¦
    
    Args:
        results_dir: ç»“æœç›®å½•
        mode: åˆ†ææ¨¡å¼
        user_config: ç”¨æˆ·é…ç½®
    """
    try:
        summary_file = results_dir / 'analysis_summary_for_user.txt'
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ğŸ“ BERTopicä¸»é¢˜åˆ†æç»“æœæ‘˜è¦\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"ğŸ“Š åˆ†ææ¨¡å¼: {mode}\n")
            f.write(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            
            # æ•°æ®ä¿¡æ¯
            data_paths = user_config.get('data_paths', {})
            f.write("ğŸ“ åˆ†ææ•°æ®:\n")
            if data_paths.get('media_data'):
                f.write(f"  - ä¼ ç»Ÿåª’ä½“æ•°æ®: {data_paths['media_data']}\n")
            if data_paths.get('social_media_data'):
                f.write(f"  - ç¤¾äº¤åª’ä½“æ•°æ®: {data_paths['social_media_data']}\n")
            f.write("\n")
            
            # åˆ†æè®¾ç½®
            f.write("âš™ï¸ åˆ†æè®¾ç½®:\n")
            topic_config = user_config.get('topic_modeling', {})
            f.write(f"  - ä¸»é¢˜æ•°é‡: {topic_config.get('target_topics', 'auto')}\n")
            f.write(f"  - æœ€å°ä¸»é¢˜å¤§å°: {topic_config.get('min_topic_size', 15)}\n")
            f.write(f"  - å…³é”®è¯ç²¾åº¦: {topic_config.get('keyword_precision', 'standard')}\n")
            f.write(f"  - è¯­è¨€æ¨¡å¼: {topic_config.get('language_mode', 'multilingual')}\n\n")
            
            # åŠŸèƒ½å¯ç”¨çŠ¶æ€
            analysis_mode_config = user_config.get('analysis_mode', {})
            f.write("ğŸ”§ åŠŸèƒ½å¯ç”¨çŠ¶æ€:\n")
            f.write(f"  - è¶…å‚æ•°ä¼˜åŒ–: {'âœ“' if analysis_mode_config.get('enable_hyperparameter_optimization') else 'âœ—'}\n")
            f.write(f"  - å¤šè¯­è¨€å¤„ç†: {'âœ“' if analysis_mode_config.get('enable_multilingual_processing') else 'âœ—'}\n")
            f.write(f"  - å­¦æœ¯çº§å¯è§†åŒ–: {'âœ“' if analysis_mode_config.get('enable_academic_visualizations') else 'âœ—'}\n")
            f.write(f"  - æ—¶é—´åˆ†æ: {'âœ“' if user_config.get('temporal_analysis', {}).get('enable') else 'âœ—'}\n")
            f.write(f"  - æ¥æºåˆ†æ: {'âœ“' if user_config.get('source_analysis', {}).get('enable') else 'âœ—'}\n")
            f.write(f"  - æ¡†æ¶åˆ†æ: {'âœ“' if user_config.get('frame_analysis', {}).get('enable') else 'âœ—'}\n\n")
            
            # ç»“æœæ–‡ä»¶
            f.write("ğŸ“„ ä¸»è¦ç»“æœæ–‡ä»¶:\n")
            f.write("  - topics_summary.csv: ä¸»é¢˜å…³é”®è¯å’Œç»Ÿè®¡ä¿¡æ¯\n")
            f.write("  - document_topic_mapping.csv: æ–‡æ¡£ä¸ä¸»é¢˜çš„å¯¹åº”å…³ç³»\n")
            f.write("  - charts_summary.txt: ç”Ÿæˆçš„å›¾è¡¨æ¸…å•\n")
            f.write("  - å›¾è¡¨æ–‡ä»¶å¤¹: åŒ…å«æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨\n\n")
            
            # ä½¿ç”¨å»ºè®®
            f.write("ğŸ’¡ ç»“æœä½¿ç”¨å»ºè®®:\n")
            f.write("  1. æŸ¥çœ‹ topics_summary.csv äº†è§£å‘ç°çš„ä¸»é¢˜\n")
            f.write("  2. æŸ¥çœ‹å›¾è¡¨æ–‡ä»¶å¤¹ä¸­çš„å¯è§†åŒ–ç»“æœ\n")
            f.write("  3. å¦‚éœ€è°ƒæ•´ï¼Œä¿®æ”¹ config.yaml ä¸­çš„å‚æ•°é‡æ–°è¿è¡Œ\n")
            f.write("  4. è®ºæ–‡å†™ä½œå¯ç›´æ¥ä½¿ç”¨ç”Ÿæˆçš„é«˜è´¨é‡å›¾è¡¨\n\n")
            
            f.write("=" * 60 + "\n")
            f.write("ğŸ‰ åˆ†æå®Œæˆï¼å¦‚æœ‰é—®é¢˜è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚\n")
            f.write("=" * 60 + "\n")
        
        print(f"ğŸ“‹ ç”¨æˆ·æ‘˜è¦å·²ç”Ÿæˆ: {summary_file}")
        
    except Exception as e:
        print(f"âš ï¸ ç”¨æˆ·æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")


def generate_analysis_summary(results_dir: Path, user_config: dict, candidate_num: int):
    """
    ç”Ÿæˆåˆ†æé˜¶æ®µçš„ç»“æœæ‘˜è¦
    
    Args:
        results_dir: ç»“æœç›®å½•
        user_config: ç”¨æˆ·é…ç½®
        candidate_num: å€™é€‰å‚æ•°ç¼–å·
    """
    try:
        summary_file = results_dir / f'å€™é€‰{candidate_num}_åˆ†ææ‘˜è¦.txt'
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write(f"ğŸ“ å€™é€‰å‚æ•° {candidate_num} åˆ†æç»“æœæ‘˜è¦\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"ğŸ¯ ä½¿ç”¨å€™é€‰: ç¬¬ {candidate_num} ç»„å‚æ•°\n\n")
            
            # å€™é€‰å‚æ•°ä¿¡æ¯
            candidate_config = user_config.get('candidate_parameters', {})
            if f'candidate_{candidate_num}' in candidate_config:
                candidate = candidate_config[f'candidate_{candidate_num}']
                f.write("ğŸ“Š å‚æ•°ä¿¡æ¯:\n")
                f.write(f"  - ä¸€è‡´æ€§åˆ†æ•°: {candidate.get('coherence_score', 'N/A')}\n")
                f.write(f"  - å‚æ•°ç‰¹å¾: {candidate.get('description', 'æœªçŸ¥')}\n")
                f.write(f"  - æœ€å°ä¸»é¢˜å¤§å°: {candidate.get('min_topic_size', 'N/A')}\n")
                f.write(f"  - UMAPé‚»å±…æ•°: {candidate.get('n_neighbors', 'N/A')}\n")
                f.write(f"  - èšç±»å¤§å°: {candidate.get('min_cluster_size', 'N/A')}\n\n")
            
            # æ•°æ®ä¿¡æ¯
            data_paths = user_config.get('data_paths', {})
            f.write("ğŸ“ åˆ†ææ•°æ®:\n")
            if data_paths.get('media_data'):
                f.write(f"  - ä¼ ç»Ÿåª’ä½“æ•°æ®: {data_paths['media_data']}\n")
            if data_paths.get('social_media_data'):
                f.write(f"  - ç¤¾äº¤åª’ä½“æ•°æ®: {data_paths['social_media_data']}\n")
            f.write("\n")
            
            # ç»“æœæ–‡ä»¶
            f.write("ğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:\n")
            f.write("  - ä¸»é¢˜å…³é”®è¯è¡¨.csv: å‘ç°çš„ä¸»é¢˜åŠå…³é”®è¯\n")
            f.write("  - æ–‡æ¡£ä¸»é¢˜æ˜ å°„è¡¨.csv: æ¯ä¸ªæ–‡æ¡£çš„ä¸»é¢˜å½’å±\n")
            f.write("  - å›¾è¡¨æ–‡ä»¶: è®ºæ–‡çº§å¯è§†åŒ–å›¾è¡¨\n")
            f.write("  - åˆ†ææŠ¥å‘Š: è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯\n\n")
            
            f.write("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:\n")
            f.write("  1. æŸ¥çœ‹ä¸»é¢˜å…³é”®è¯è¡¨ï¼Œè¯„ä¼°ä¸»é¢˜è´¨é‡\n")
            f.write("  2. æ£€æŸ¥å›¾è¡¨æ–‡ä»¶ï¼Œç¡®è®¤å¯è§†åŒ–æ•ˆæœ\n")
            f.write("  3. å¦‚éœ€å¯¹æ¯”ï¼Œå¯é€‰æ‹©å…¶ä»–å€™é€‰å‚æ•°é‡æ–°åˆ†æ\n")
            f.write("  4. é€‰å®šæœ€ä½³å‚æ•°åï¼Œå¯ç”¨äºè®ºæ–‡å†™ä½œ\n\n")
            
            f.write("=" * 60 + "\n")
            f.write(f"ğŸ‰ å€™é€‰ {candidate_num} åˆ†æå®Œæˆï¼\n")
            f.write("=" * 60 + "\n")
        
        print(f"ğŸ“‹ åˆ†ææ‘˜è¦å·²ç”Ÿæˆ: {summary_file}")
        
    except Exception as e:
        print(f"âš ï¸ åˆ†ææ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")


def run_advanced_analysis(mode: str = 'standard') -> bool:
    """
    è¿è¡Œé«˜çº§åˆ†æï¼ˆå‘åå…¼å®¹ï¼‰
    
    Args:
        mode: åˆ†ææ¨¡å¼ (quick/standard/research)
    """
    # ä¸ºå‘åå…¼å®¹ä¿ç•™æ­¤å‡½æ•°ï¼Œä½†å»ºè®®ä½¿ç”¨ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    return run_user_friendly_analysis()


def create_cli_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="BERTopicä¸»é¢˜åˆ†æç³»ç»Ÿ - åšå£«ç”Ÿå‹å¥½ç‰ˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ“ ä½¿ç”¨è¯´æ˜ï¼ˆä¸“ä¸ºè®¡ç®—ä¼ æ’­å­¦åšå£«ç”Ÿè®¾è®¡ï¼‰:
  
  python main.py                    # äº¤äº’å¼ç•Œé¢ï¼ˆæ¨èï¼‰
  python main.py --run              # ç›´æ¥è¿è¡Œåˆ†æï¼ˆè¯»å–config.yamlï¼‰
  python main.py --check            # æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ
  
ğŸ’¡ æ‰€æœ‰åˆ†æå‚æ•°éƒ½åœ¨ config.yaml æ–‡ä»¶ä¸­è®¾ç½®ï¼š
  - æ•°æ®æ–‡ä»¶è·¯å¾„
  - åˆ†ææ¨¡å¼é€‰æ‹©  
  - ä¸»é¢˜æ•°é‡å’Œç²¾åº¦
  - å¯è§†åŒ–è®¾ç½®
  
ğŸ“ è®ºæ–‡å†™ä½œæµç¨‹ï¼š
  1. ä¿®æ”¹ config.yaml è®¾ç½®å‚æ•°
  2. è¿è¡Œ python main.py --run
  3. æŸ¥çœ‹ results/ æ–‡ä»¶å¤¹è·å–ç»“æœ
  4. ä½¿ç”¨ç”Ÿæˆçš„é«˜è´¨é‡å›¾è¡¨å†™è®ºæ–‡
        """
    )
    
    parser.add_argument(
        '--run', '-r',
        action='store_true',
        help='ç›´æ¥è¿è¡Œåˆ†æï¼ˆè¯»å–config.yamlé…ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--check', '-c',
        action='store_true',
        help='ä»…æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ'
    )
    
    parser.add_argument(
        '--config',
        type=str,
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)'
    )
    
    return parser


if __name__ == "__main__":
    try:
        parser = create_cli_parser()
        args = parser.parse_args()
        
        # æ£€æŸ¥å‚æ•°
        if args.run:
            # ç›´æ¥è¿è¡Œåˆ†æ
            print("ğŸ¯ ç›´æ¥è¿è¡Œæ¨¡å¼ï¼šè¯»å– config.yaml é…ç½®...")
            success = run_user_friendly_analysis()
            sys.exit(0 if success else 1)
            
        elif args.check:
            # ä»…ç¯å¢ƒæ£€æŸ¥
            print("ğŸ” ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥...")
            checks = [
                ("Pythonç‰ˆæœ¬", check_python_version),
                ("ä¾èµ–åŒ…", check_dependencies),
                ("é…ç½®æ–‡ä»¶", lambda: validate_config(Path(args.config))),
                ("æ•°æ®æ–‡ä»¶", check_data_files),
            ]
            
            all_passed = True
            for check_name, check_func in checks:
                print(f"\næ£€æŸ¥{check_name}...")
                if not check_func():
                    all_passed = False
            
            if all_passed:
                print("\nâœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œç³»ç»Ÿå°±ç»ª")
                print("ğŸ’¡ å¯ä»¥è¿è¡Œ: python main.py --run å¼€å§‹åˆ†æ")
                sys.exit(0)
            else:
                print("\nâŒ æ£€æŸ¥å¤±è´¥ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜")
                sys.exit(1)
        else:
            # äº¤äº’å¼æ¨¡å¼
        main()
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­è¿è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)