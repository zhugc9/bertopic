================================================================================
                   BERTopic 增强议题分析系统
                    AI开发者完整技术文档 v2.0
================================================================================

【项目状态】PRODUCTION READY
- 版本: v2.0 Enhanced Edition
- 代码状态: 完整实现，所有模块可运行
- 测试状态: 功能验证完成
- 部署状态: 支持本地部署和Web界面

【核心架构】
基于BERTopic的企业级主题建模系统，集成5大专业模块：
1. 专家级关键词提取 (Expert Keyword Extraction)
2. 出版级学术图表 (Academic Charts)  
3. 动态主题演化 (Dynamic Evolution)
4. 跨语言成分分析 (Cross-Lingual Analysis)
5. 交互式Web界面 (Streamlit Web UI)

技术栈：Python 3.8+ | BERTopic 0.16.0 | spaCy | Streamlit | Plotly

================================================================================
                           完整文件结构
================================================================================

bertopic/
├── 🎯 核心引擎
│   ├── main.py                         # 主控制器，执行完整pipeline
│   ├── topic_analyzer/                 # 核心分析模块包
│   │   ├── __init__.py                # 模块导出：DataLoader, TopicAnalyzer
│   │   ├── data_loader.py             # Excel ETL处理器，支持多源数据合并
│   │   ├── model.py                   # BERTopic模型封装，集成所有增强功能
│   │   ├── expert_keywords.py         # 词性标注+自定义停用词的关键词提取
│   │   ├── academic_charts.py         # 高分辨率PNG/PDF学术图表生成
│   │   ├── dynamic_evolution.py       # 时间序列主题演化分析
│   │   └── cross_lingual.py          # 中英俄三语文档语言构成分析
│   └── config.yaml                    # 超参数配置：模型+分析+可视化参数
├── 💻 用户界面
│   ├── web_ui.py                      # Streamlit Web应用，完整GUI界面
│   ├── quick_start.py                 # 命令行启动器，环境检测+交互式运行
│   ├── topic_labeler.py               # LLM API集成，自动生成中文主题标签
│   └── validate_config.py             # 配置文件验证工具
├── 🛠️ 部署脚本
│   ├── 启动分析.bat                   # Windows一键安装+运行
│   ├── run_web_ui.bat                 # Web界面启动脚本
│   └── requirements.txt               # 完整依赖清单，包含新增模块
├── 📊 资源文件
│   ├── stopwords/                     # 自定义停用词库
│   │   └── politics_stopwords.txt    # 政治新闻专用停用词（中英俄三语）
│   ├── data/ (用户创建)               # 输入Excel文件目录
│   └── results/ (自动生成)            # 输出结果目录
└── 📚 文档
    ├── README.md                      # 用户友好的项目说明
    ├── 增强功能使用说明.md            # 五大模块详细使用指南
    └── 喂给ai的开发者说明.txt         # 本文件，AI技术参考

================================================================================
                         数据流和API接口
================================================================================

【输入数据规范】
格式: Excel OOXML (.xlsx)
必需文件:
- data/媒体_最终分析数据库.xlsx
- data/社交媒体_最终分析数据库.xlsx

Schema要求:
```python
# 必需字段
text_column: str (default: "Incident")     # 主文本内容

# 可选字段（用于增强分析）  
Source: str                               # 数据来源标识
日期: datetime                            # 时间戳，用于演化分析
speaker: str                             # 发言者信息
Valence: str                             # 情感倾向
Frame_*_Present: bool                    # 新闻框架二值特征
```

【输出结果API】
results/ 目录结构:
```
├── 基础分析文件
│   ├── topics_summary.csv              # 原始主题摘要
│   ├── topics_summary_enhanced.csv     # 增强主题摘要（包含语言构成）
│   ├── cross_lingual_composition.csv   # 跨语言分析详细报告
│   ├── dynamic_evolution_analysis.csv  # 动态演化数据
│   └── comprehensive_analysis_report.txt # 综合分析总结
├── 学术级图表 (PNG + PDF)
│   ├── academic_topic_distribution.*   # 二维主题分布图
│   ├── academic_topic_sizes.*          # 主题规模南丁格尔图
│   ├── academic_topic_evolution.*      # 主题时间演化图
│   └── cross_lingual_analysis.*        # 跨语言成分图
├── 交互式可视化 (HTML)
│   ├── topic_visualization.html        # 主题关系交互图
│   ├── topic_by_source.html           # 来源对比图表
│   ├── topics_over_time.html          # 时间演化交互图
│   └── topic_frame_heatmap.html       # 框架关联热力图
└── 模型文件
    └── trained_model/                  # BERTopic模型序列化文件
```

数据格式规范:
- CSV: UTF-8 encoding, pandas-compatible
- HTML: Plotly standalone, 无外部依赖
- PNG/PDF: 300 DPI, 学术出版级质量
- Model: safetensors + CTFIDF matrices

================================================================================
                         核心算法实现
================================================================================

【主题建模Pipeline】
```python
1. Data Loading (data_loader.py)
   ├── Excel读取: pandas.read_excel() 
   ├── 数据合并: concat/merge策略
   ├── 文本清洗: 长度过滤、编码处理
   └── 元数据提取: 时间、来源、框架字段

2. Expert Keyword Extraction (expert_keywords.py)
   ├── 语言检测: langdetect自动识别中英俄
   ├── 词性标注: spaCy (zh_core_web_sm, en_core_web_sm, ru_core_news_sm)
   ├── 短语模式: 正则匹配 '<n.*|a.*>*<n.*>+' (中文)
   ├── 停用词过滤: 政治新闻专用词库
   └── 增强向量化: CountVectorizer + 自定义tokenizer

3. Topic Modeling (model.py)
   ├── 嵌入: SentenceTransformers多语言模型
   ├── 降维: UMAP (n_neighbors=15, n_components=5, cosine)
   ├── 聚类: HDBSCAN (min_cluster_size=15, euclidean)
   ├── 表示: KeyBERTInspired + MaximalMarginalRelevance
   └── 概率: calculate_probabilities=True

4. Enhanced Analysis
   ├── Cross-Lingual (cross_lingual.py): 语言构成统计
   ├── Dynamic Evolution (dynamic_evolution.py): 时间序列分析
   ├── Academic Charts (academic_charts.py): 高质量静态图表
   └── Comprehensive Report: 自动生成分析总结
```

【关键算法参数】
```yaml
# 核心BERTopic配置
bertopic_params:
  embedding_model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  min_topic_size: 15                    # 可调: 5-100
  nr_topics: "auto"                     # 可设具体数字
  n_gram_range: [1, 3]                  # 词汇组合范围
  
  # 专家级关键词提取
  expert_keyword_extraction:
    enable_pos_patterns: true           # 启用词性模式
    pos_patterns:
      zh: '<n.*|a.*>*<n.*>+'           # 中文语法规则
      en: '<JJ.*>*<NN.*>+'             # 英文语法规则  
      ru: '<A.*>*<N.*>+'               # 俄文语法规则
    custom_stopwords_path: "stopwords/politics_stopwords.txt"
    use_custom_stopwords: true
    pos_language_detection: true        # 自动语言检测

  # UMAP降维优化
  umap_params:
    n_neighbors: 15                     # 邻居数，影响局部vs全局平衡
    n_components: 5                     # 降维维度
    min_dist: 0.0                       # 嵌入距离，0.0=紧密聚类
    metric: "cosine"                    # 距离度量，适合文本
    random_state: 42                    # 可重现性

  # HDBSCAN聚类优化  
  hdbscan_params:
    min_cluster_size: 15                # 最小聚类大小
    min_samples: 5                      # 核心点阈值
    metric: "euclidean"                 # 聚类距离
    cluster_selection_method: "eom"     # 基于密度的选择
    prediction_data: true               # 支持新文档预测
```

================================================================================
                         增强模块详细说明
================================================================================

【模块1: 专家级关键词提取】
文件: topic_analyzer/expert_keywords.py
核心类: ExpertKeywordExtractor

功能:
- 基于spaCy的词性标注，识别完整政治术语
- 支持中英俄三语混合文本处理
- 自定义停用词库过滤无意义词汇
- 增强BERTopic的CountVectorizer

关键方法:
```python
detect_language(text: str) -> str              # 自动语言检测
extract_pos_phrases(text: str) -> List[str]    # 基于词性的短语提取
create_enhanced_vectorizer() -> CountVectorizer # 增强向量化器
enhance_topic_representation() -> Dict         # 主题表示增强
```

依赖:
- spacy >= 3.4.0
- langdetect == 1.0.9
- 语言模型: zh_core_web_sm, en_core_web_sm, ru_core_news_sm

【模块2: 出版级学术图表】
文件: topic_analyzer/academic_charts.py  
核心类: AcademicChartGenerator

功能:
- 生成300 DPI高分辨率PNG + PDF图表
- 二维主题分布图（t-SNE降维 + 注释）
- 南丁格尔玫瑰图（主题规模可视化）
- 符合学术论文发表标准

关键方法:
```python
generate_topic_distribution_chart() -> str     # 2D主题分布图
generate_topic_size_chart() -> str            # 玫瑰图规模图
generate_topic_evolution_chart() -> str       # 时间演化图
generate_heatmap_chart() -> str               # 热力图
```

图表特性:
- 字体: Times New Roman serif
- 分辨率: 300 DPI
- 格式: PNG (在线) + PDF (印刷)
- 配色: 学术期刊标准色

【模块3: 动态主题演化】
文件: topic_analyzer/dynamic_evolution.py
核心类: DynamicTopicEvolution

功能:
- BERTopic官方topics_over_time方法集成
- 主题诞生/消亡时间点检测  
- 演化模式分类（上升/下降/稳定/波动/季节性）
- 时间段自适应分箱

关键方法:
```python
analyze_dynamic_topics() -> pd.DataFrame       # 动态主题分析
analyze_topic_birth_death() -> Dict           # 诞生消亡分析
detect_topic_evolution_patterns() -> Dict     # 演化模式检测
```

分析维度:
- 时间趋势: 线性回归斜率分析
- 波动性: 标准差和变异系数
- 季节性: 自相关检测
- 生命周期: 首次/最后出现时间

【模块4: 跨语言成分分析】
文件: topic_analyzer/cross_lingual.py
核心类: CrossLingualAnalyzer

功能:
- 文档级语言自动检测（中英俄+混合+未知）
- 主题级语言构成统计和分类
- 中俄关系研究专用的议题类型识别
- 语言平衡度可视化

关键方法:
```python
detect_document_language(text: str) -> str     # 单文档语言检测
analyze_topic_language_composition() -> DataFrame # 主题语言构成
generate_language_distribution_chart() -> str  # 语言分布可视化
```

语言检测规则:
```python
language_patterns = {
    'zh': re.compile(r'[\u4e00-\u9fff]'),      # 中文字符
    'ru': re.compile(r'[\u0400-\u04ff]'),      # 俄文字符
    'en': re.compile(r'^[a-zA-Z\s\d\.,!?\-\'\"]*$') # 英文字符
}
```

主题分类逻辑:
- Chinese-Dominant: 中文占70%+
- Russian-Dominant: 俄文占70%+  
- Sino-Russian: 中俄文档合计80%+
- Balanced-Multilingual: 中俄差异<20%且合计50%+

【模块5: 交互式Web界面】
文件: web_ui.py
核心类: BERTopicWebUI

功能:
- Streamlit框架的现代化Web界面
- 拖拽文件上传 + 实时参数调节
- 进度条显示 + 结果在线预览
- 一键下载所有结果文件

界面结构:
```python
tabs = ["📁 数据上传", "⚙️ 参数配置", "🚀 运行分析", "📊 结果查看"]
```

关键功能:
- 文件验证: Excel格式和列名检查
- 参数配置: 滑块/选择框动态调节
- 任务执行: 进度条 + 状态显示
- 结果管理: ZIP打包下载

================================================================================
                         配置系统详解
================================================================================

【config.yaml 结构】
```yaml
# 数据文件路径
data_paths:
  media_data: "data/媒体_最终分析数据库.xlsx"
  social_media_data: "data/社交媒体_最终分析数据库.xlsx"

# 输出路径配置
results_paths:
  output_dir: "results"
  summary_file: "results/topics_summary.csv"
  academic_charts:                      # 新增：学术图表路径
    topic_distribution: "results/academic_topic_distribution.png"
    topic_sizes: "results/academic_topic_sizes.png"

# 数据处理配置
data_processing:
  text_column: "Incident"               # 主文本列
  merge_strategy: "concat"              # 数据合并策略
  metadata_columns:                     # 保留的元数据列
    - "Source"
    - "日期"  
    - "speaker"
    - "Valence"
    - "Frame_*_Present"

# BERTopic核心参数
bertopic_params:
  language: "multilingual"
  embedding_model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  min_topic_size: 15
  nr_topics: "auto"
  
  # 新增：专家级关键词提取配置
  expert_keyword_extraction:
    enable_pos_patterns: true
    pos_patterns:
      zh: '<n.*|a.*>*<n.*>+'
      en: '<JJ.*>*<NN.*>+'  
      ru: '<A.*>*<N.*>+'
    custom_stopwords_path: "stopwords/politics_stopwords.txt"
    use_custom_stopwords: true

# 分析功能开关
analysis:
  time_analysis:
    enable: true
    time_column: "日期"
    bins: 10
  source_analysis:
    enable: true
  frame_analysis:
    enable: true
```

【配置验证】
文件: validate_config.py
功能: 配置文件完整性和参数合理性检查

验证项目:
- 文件路径存在性检查
- 参数范围合理性验证  
- 列名配置正确性检查
- 依赖包安装状态验证

================================================================================
                         部署和运行方式
================================================================================

【方式1: Windows一键部署】
脚本: 启动分析.bat
```batch
# 自动检测conda环境
# 首次运行: 创建bertopic_lab环境 + 安装依赖
# 后续运行: 直接激活环境 + 执行分析
conda activate bertopic_lab && python quick_start.py
```

【方式2: Web界面模式】  
脚本: run_web_ui.bat
```batch
conda activate bertopic_lab && streamlit run web_ui.py
```

【方式3: 手动命令行】
```bash
# 环境准备
conda create --name bertopic_lab python=3.9 -y
conda activate bertopic_lab
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# 安装语言模型
python -m spacy download zh_core_web_sm
python -m spacy download en_core_web_sm
python -m spacy download ru_core_news_sm

# 运行分析
python main.py                    # 直接运行
python quick_start.py             # 环境检查+交互式
python web_ui.py                  # Web界面 (需streamlit run)
python topic_labeler.py           # 后处理标签生成
```

【方式4: Docker容器化（预留）】
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "main.py"]
```

================================================================================
                         性能和优化
================================================================================

【计算复杂度】
- 嵌入: O(n×m×d) n=docs, m=tokens, d=embed_dim
- UMAP: O(n^1.14) 近似  
- HDBSCAN: O(n×log(n)) 平均
- 专家提取: O(n×k) k=平均文档长度
- 跨语言分析: O(n) 线性
- 总体: O(n×m×d + n^1.14)

【实测性能 (Intel i7, 16GB RAM)】
- 1K docs: ~2-5分钟
- 10K docs: ~15-30分钟
- 100K docs: ~2-4小时  
- 内存需求: ~2GB per 10K docs

【优化建议】
大数据集配置:
```yaml
bertopic_params:
  min_topic_size: 30              # 提高阈值减少计算
  calculate_probabilities: false  # 禁用概率计算
  expert_keyword_extraction:
    pos_language_detection: false # 如果已知语言可关闭检测
system:
  use_gpu: true                   # 启用GPU加速（如果可用）
```

内存优化:
- 分批处理: 将大数据集分割为多个批次
- 减少特征: 降低n_gram_range上限
- 模型简化: 使用较小的嵌入模型

================================================================================
                         错误处理和调试
================================================================================

【日志系统】
主日志文件: bertopic_analysis.log
日志级别: INFO, WARNING, ERROR
编码: UTF-8

【常见错误及解决】
1. spaCy模型缺失
   错误: "OSError: Can't find model 'zh_core_web_sm'"
   解决: python -m spacy download zh_core_web_sm

2. 内存不足
   错误: "MemoryError" / "OutOfMemoryError"  
   解决: 增大min_topic_size或分批处理

3. 编码问题
   错误: "UnicodeDecodeError"
   解决: 确保Excel文件UTF-8编码

4. 依赖版本冲突
   错误: "ImportError" / "AttributeError"
   解决: pip install -r requirements.txt --force-reinstall

5. Web界面端口占用
   错误: "OSError: [Errno 48] Address already in use"
   解决: streamlit run web_ui.py --server.port 8502

【调试工具】
- validate_config.py: 配置文件检查
- quick_start.py: 环境诊断
- 日志分析: tail -f bertopic_analysis.log

================================================================================
                         扩展和二次开发
================================================================================

【模块化设计】
每个增强模块都是独立的类，可以单独使用:
```python
from topic_analyzer.expert_keywords import ExpertKeywordExtractor
from topic_analyzer.cross_lingual import CrossLingualAnalyzer

# 单独使用跨语言分析
analyzer = CrossLingualAnalyzer(config)
results = analyzer.run_full_cross_lingual_analysis(documents, topics)
```

【API扩展点】
1. 自定义嵌入模型
```python
custom_model = SentenceTransformer('your-model-name')
```

2. 自定义预处理pipeline
```python
def custom_preprocessor(texts: List[str]) -> List[str]:
    return [preprocess(text) for text in texts]
```

3. 自定义主题表示
```python
from bertopic.representation import MaximalMarginalRelevance
custom_repr = MaximalMarginalRelevance(diversity=0.5)
```

4. 自定义可视化
```python
def custom_visualization(topic_model, documents):
    # 实现自定义图表逻辑
    pass
```

【数据接口扩展】
- 支持JSON/CSV输入: 修改data_loader.py
- 支持数据库连接: 添加SQLAlchemy集成
- 支持实时流数据: 添加Kafka/Redis集成
- 支持API服务: 添加FastAPI封装

【新增语言支持】
1. 在pos_patterns中添加新语言语法规则
2. 下载对应的spaCy语言模型
3. 更新language_patterns正则表达式
4. 在custom_stopwords中添加新语言停用词

================================================================================
                         学术和商业应用
================================================================================

【学术研究应用】
- 国际关系: 中俄关系议题演化分析
- 传播学: 媒体框架和议程设置研究
- 政治学: 政策议题分类和舆论分析
- 社会学: 跨文化交流模式研究

【商业应用场景】  
- 媒体监测: 品牌提及和危机预警
- 市场研究: 消费者关注点变化追踪
- 竞争分析: 行业议题热点发现
- 内容策略: 内容主题规划和优化

【输出标准】
- 学术论文: 300 DPI PNG/PDF图表
- 研究报告: 详细的CSV数据表
- 商业展示: 交互式HTML可视化
- 技术文档: 完整的分析日志

【引用格式】
BibTeX:
```bibtex
@software{bertopic_enhanced_2025,
  title={BERTopic Enhanced Analysis System v2.0},
  author={Development Team},
  year={2025},
  note={Enhanced with Expert Keyword Extraction, Academic Visualization, 
        Dynamic Evolution Analysis, Cross-Lingual Topic Composition, and Web UI}
}
```

================================================================================
                           开发者快速参考
================================================================================

【核心类导入】
```python
from topic_analyzer import DataLoader, TopicAnalyzer
from topic_analyzer.expert_keywords import ExpertKeywordExtractor
from topic_analyzer.academic_charts import AcademicChartGenerator  
from topic_analyzer.dynamic_evolution import DynamicTopicEvolution
from topic_analyzer.cross_lingual import CrossLingualAnalyzer
```

【最小可运行示例】
```python
import yaml
from topic_analyzer import DataLoader, TopicAnalyzer

# 加载配置
with open('config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# 数据加载
data_loader = DataLoader(config)
documents, metadata_df = data_loader.load_and_prepare_data()

# 模型训练
analyzer = TopicAnalyzer(config)
topic_model, topics = analyzer.train_bertopic_model(documents)

# 增强分析
enhanced_topics = analyzer.expert_extractor.enhance_topic_representation(
    topic_model, documents
)
analyzer.generate_enhanced_results(
    topic_model, documents, topics, metadata_df, enhanced_topics
)
```

【关键配置参数】
```python
# 性能优化
min_topic_size = max(10, len(documents) // 200)

# 质量优化  
enable_pos_patterns = True
use_custom_stopwords = True

# 输出控制
calculate_probabilities = False  # 大数据集时禁用
save_intermediate = False        # 调试时启用
```

【常用调试命令】
```bash
# 验证配置
python validate_config.py

# 环境检查  
python quick_start.py

# 直接运行
python main.py

# Web界面
streamlit run web_ui.py

# 后处理标签
python topic_labeler.py
```

================================================================================
                               版本历史
================================================================================

v2.0.0 (当前版本) - Enhanced Edition
✅ 专家级关键词提取模块 (expert_keywords.py)
✅ 出版级学术图表生成 (academic_charts.py)  
✅ 动态主题演化分析 (dynamic_evolution.py)
✅ 跨语言成分分析 (cross_lingual.py)
✅ 交互式Web界面 (web_ui.py)
✅ 政治新闻停用词库 (politics_stopwords.txt)
✅ 完整的配置验证系统
✅ 综合分析报告生成

v1.0.0 - 基础版本
✅ 基础BERTopic主题建模
✅ 简单HTML可视化输出
✅ 命令行界面操作

计划功能 (v3.0):
🔄 实时数据流处理
🔄 更多可视化选项 (3D图表、动画)
🔄 API服务化部署 (FastAPI)
🔄 多语言界面支持
🔄 云端部署支持 (Docker + K8s)

================================================================================
                               文档结束
================================================================================

最后更新: 2025年9月20日
文档版本: v2.0 Complete Technical Reference
项目状态: Production Ready - 所有功能已实现并可投入使用

本文档为AI开发者提供完整的技术参考，包含所有实现细节、配置参数、
API接口、扩展方法和调试信息。基于此文档，AI可以立即理解和操作整个项目。