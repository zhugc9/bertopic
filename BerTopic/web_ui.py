"""
äº¤äº’å¼Webåº”ç”¨ç•Œé¢
================
ä½¿ç”¨Streamlitåˆ›å»ºç”¨æˆ·å‹å¥½çš„å›¾å½¢ç•Œé¢
"""

import streamlit as st
import pandas as pd
import numpy as np
import yaml
import logging
import tempfile
import zipfile
from pathlib import Path
from io import StringIO, BytesIO
import sys
import subprocess
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px

# ç¡®ä¿èƒ½æ‰¾åˆ°é¡¹ç›®æ¨¡å—
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from topic_analyzer.data_loader import DataLoader
from topic_analyzer.model import TopicAnalyzer

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="BERTopic è®®é¢˜åˆ†æç³»ç»Ÿ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }
    .module-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #ff7f0e;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


class BERTopicWebUI:
    """BERTopic Webç•Œé¢ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–Webç•Œé¢"""
        self.config = self._load_default_config()
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = None
        if 'uploaded_files' not in st.session_state:
            st.session_state.uploaded_files = {}
    
    def _load_default_config(self) -> dict:
        """åŠ è½½é»˜è®¤é…ç½®"""
        default_config = {
            'data_paths': {
                'media_data': 'temp/media_data.xlsx',
                'social_media_data': 'temp/social_media_data.xlsx'
            },
            'results_paths': {
                'output_dir': 'temp/results',
                'model_dir': 'temp/results/trained_model',
                'summary_file': 'temp/results/topics_summary.csv',
                'viz_file': 'temp/results/topic_visualization.html',
                'source_analysis': 'temp/results/topic_by_source.html',
                'timeline_analysis': 'temp/results/topics_over_time.html',
                'frame_heatmap': 'temp/results/topic_frame_heatmap.html',
                'academic_charts': {
                    'topic_distribution': 'temp/results/academic_topic_distribution.png',
                    'topic_sizes': 'temp/results/academic_topic_sizes.png',
                    'topic_evolution': 'temp/results/academic_topic_evolution.png',
                    'cross_lingual': 'temp/results/academic_cross_lingual.png'
                }
            },
            'data_processing': {
                'text_column': 'Incident',
                'merge_strategy': 'concat',
                'metadata_columns': ['Source', 'æ—¥æœŸ', 'speaker', 'Valence']
            },
            'bertopic_params': {
                'language': 'multilingual',
                'embedding_model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                'min_topic_size': 15,
                'nr_topics': 'auto',
                'n_gram_range': [1, 3],
                'expert_keyword_extraction': {
                    'enable_pos_patterns': True,
                    'pos_patterns': {
                        'zh': '<n.*|a.*>*<n.*>+',
                        'en': '<JJ.*>*<NN.*>+',
                        'ru': '<A.*>*<N.*>+'
                    },
                    'custom_stopwords_path': 'stopwords/politics_stopwords.txt',
                    'use_custom_stopwords': True,
                    'pos_language_detection': True
                },
                'umap_params': {
                    'n_neighbors': 15,
                    'n_components': 5,
                    'min_dist': 0.0,
                    'metric': 'cosine',
                    'random_state': 42
                },
                'hdbscan_params': {
                    'min_cluster_size': 15,
                    'min_samples': 5,
                    'metric': 'euclidean',
                    'cluster_selection_method': 'eom',
                    'prediction_data': True
                }
            },
            'visualization': {
                'figsize': [12, 8],
                'dpi': 100,
                'style': 'plotly',
                'color_scheme': 'viridis',
                'save_format': 'html'
            },
            'analysis': {
                'time_analysis': {
                    'enable': True,
                    'time_column': 'æ—¥æœŸ',
                    'bins': 10
                },
                'source_analysis': {
                    'enable': True,
                    'source_column': 'Source'
                },
                'frame_analysis': {
                    'enable': True,
                    'threshold': 0.1
                }
            },
            'system': {
                'random_seed': 42,
                'verbose': True,
                'save_intermediate': False,
                'use_gpu': False
            }
        }
        return default_config
    
    def render_main_page(self):
        """æ¸²æŸ“ä¸»é¡µé¢"""
        # ä¸»æ ‡é¢˜
        st.markdown('<div class="main-header">ğŸš€ BERTopic è®®é¢˜åˆ†æç³»ç»Ÿ</div>', unsafe_allow_html=True)
        
        # ä¾§è¾¹æ 
        self._render_sidebar()
        
        # ä¸»å†…å®¹åŒºåŸŸ
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ æ•°æ®ä¸Šä¼ ", "âš™ï¸ å‚æ•°é…ç½®", "ğŸš€ è¿è¡Œåˆ†æ", "ğŸ“Š ç»“æœæŸ¥çœ‹"])
        
        with tab1:
            self._render_data_upload()
        
        with tab2:
            self._render_parameter_config()
        
        with tab3:
            self._render_analysis_runner()
        
        with tab4:
            self._render_results_viewer()
    
    def _render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.sidebar.markdown("### ğŸ¯ å¿«é€Ÿå¯¼èˆª")
        
        # ç³»ç»ŸçŠ¶æ€
        st.sidebar.markdown("#### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶çŠ¶æ€
        media_uploaded = 'media_data' in st.session_state.uploaded_files
        social_uploaded = 'social_media_data' in st.session_state.uploaded_files
        
        st.sidebar.write(f"åª’ä½“æ•°æ®: {'âœ…' if media_uploaded else 'âŒ'}")
        st.sidebar.write(f"ç¤¾äº¤åª’ä½“æ•°æ®: {'âœ…' if social_uploaded else 'âŒ'}")
        st.sidebar.write(f"åˆ†æç»“æœ: {'âœ…' if st.session_state.analysis_results else 'âŒ'}")
        
        # å¿«é€Ÿæ“ä½œ
        st.sidebar.markdown("#### âš¡ å¿«é€Ÿæ“ä½œ")
        
        if st.sidebar.button("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®"):
            st.session_state.uploaded_files = {}
            st.session_state.analysis_results = None
            st.success("æ•°æ®å·²é‡ç½®")
        
        if st.sidebar.button("ğŸ“¥ ä¸‹è½½é…ç½®æ¨¡æ¿"):
            self._download_config_template()
        
        # å¸®åŠ©ä¿¡æ¯
        st.sidebar.markdown("#### â“ å¸®åŠ©ä¿¡æ¯")
        st.sidebar.info("""
        **ä½¿ç”¨æ­¥éª¤:**
        1. ä¸Šä¼ Excelæ•°æ®æ–‡ä»¶
        2. è°ƒæ•´åˆ†æå‚æ•°
        3. è¿è¡Œåˆ†æ
        4. æŸ¥çœ‹å’Œä¸‹è½½ç»“æœ
        
        **æ”¯æŒçš„æ–‡ä»¶æ ¼å¼:**
        - Excel (.xlsx)
        - éœ€è¦åŒ…å«æ–‡æœ¬åˆ—
        """)
    
    def _render_data_upload(self):
        """æ¸²æŸ“æ•°æ®ä¸Šä¼ ç•Œé¢"""
        st.markdown('<div class="module-header">ğŸ“ æ•°æ®æ–‡ä»¶ä¸Šä¼ </div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("åª’ä½“æ•°æ®æ–‡ä»¶")
            media_file = st.file_uploader(
                "ä¸Šä¼ åª’ä½“æ•°æ®Excelæ–‡ä»¶",
                type=['xlsx'],
                key="media_uploader",
                help="è¯·ä¸Šä¼ åŒ…å«åª’ä½“æ–‡æœ¬æ•°æ®çš„Excelæ–‡ä»¶"
            )
            
            if media_file is not None:
                # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                temp_path = self._save_uploaded_file(media_file, "media_data")
                st.session_state.uploaded_files['media_data'] = temp_path
                
                # é¢„è§ˆæ•°æ®
                try:
                    df = pd.read_excel(temp_path)
                    st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ! åŒ…å« {len(df)} è¡Œæ•°æ®")
                    
                    with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ"):
                        st.dataframe(df.head())
                        st.write(f"**åˆ—å:** {', '.join(df.columns.tolist())}")
                    
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        
        with col2:
            st.subheader("ç¤¾äº¤åª’ä½“æ•°æ®æ–‡ä»¶")
            social_file = st.file_uploader(
                "ä¸Šä¼ ç¤¾äº¤åª’ä½“æ•°æ®Excelæ–‡ä»¶",
                type=['xlsx'],
                key="social_uploader",
                help="è¯·ä¸Šä¼ åŒ…å«ç¤¾äº¤åª’ä½“æ–‡æœ¬æ•°æ®çš„Excelæ–‡ä»¶"
            )
            
            if social_file is not None:
                # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                temp_path = self._save_uploaded_file(social_file, "social_media_data")
                st.session_state.uploaded_files['social_media_data'] = temp_path
                
                # é¢„è§ˆæ•°æ®
                try:
                    df = pd.read_excel(temp_path)
                    st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ! åŒ…å« {len(df)} è¡Œæ•°æ®")
                    
                    with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ"):
                        st.dataframe(df.head())
                        st.write(f"**åˆ—å:** {', '.join(df.columns.tolist())}")
                    
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        
        # æ•°æ®éªŒè¯
        if len(st.session_state.uploaded_files) > 0:
            st.markdown("---")
            st.subheader("ğŸ” æ•°æ®éªŒè¯")
            self._validate_uploaded_data()
    
    def _render_parameter_config(self):
        """æ¸²æŸ“å‚æ•°é…ç½®ç•Œé¢"""
        st.markdown('<div class="module-header">âš™ï¸ åˆ†æå‚æ•°é…ç½®</div>', unsafe_allow_html=True)
        
        # åŸºç¡€å‚æ•°é…ç½®
        st.subheader("ğŸ“Š åŸºç¡€å‚æ•°")
        col1, col2 = st.columns(2)
        
        with col1:
            self.config['data_processing']['text_column'] = st.selectbox(
                "æ–‡æœ¬åˆ—å",
                options=['Incident', 'Unit_Text', 'Text', 'Content'],
                index=0,
                help="é€‰æ‹©åŒ…å«è¦åˆ†ææ–‡æœ¬çš„åˆ—å"
            )
            
            self.config['bertopic_params']['min_topic_size'] = st.slider(
                "æœ€å°ä¸»é¢˜å¤§å°",
                min_value=5,
                max_value=100,
                value=15,
                help="è¾ƒå°å€¼äº§ç”Ÿæ›´å¤šç»†ç²’åº¦ä¸»é¢˜ï¼Œè¾ƒå¤§å€¼äº§ç”Ÿæ›´å°‘ç²—ç²’åº¦ä¸»é¢˜"
            )
        
        with col2:
            nr_topics_auto = st.checkbox("è‡ªåŠ¨ç¡®å®šä¸»é¢˜æ•°é‡", value=True)
            if nr_topics_auto:
                self.config['bertopic_params']['nr_topics'] = 'auto'
            else:
                self.config['bertopic_params']['nr_topics'] = st.slider(
                    "ç›®æ ‡ä¸»é¢˜æ•°é‡",
                    min_value=2,
                    max_value=50,
                    value=20
                )
            
            self.config['bertopic_params']['n_gram_range'] = [
                st.selectbox("N-gram æœ€å°å€¼", [1, 2], index=0),
                st.selectbox("N-gram æœ€å¤§å€¼", [2, 3, 4], index=1)
            ]
        
        # é«˜çº§å‚æ•°é…ç½®
        st.markdown("---")
        st.subheader("ğŸ”§ é«˜çº§å‚æ•°")
        
        with st.expander("ğŸ¯ ä¸“å®¶çº§å…³é”®è¯æå–"):
            col1, col2 = st.columns(2)
            with col1:
                self.config['bertopic_params']['expert_keyword_extraction']['enable_pos_patterns'] = st.checkbox(
                    "å¯ç”¨è¯æ€§æ ‡æ³¨æ¨¡å¼", value=True
                )
                self.config['bertopic_params']['expert_keyword_extraction']['use_custom_stopwords'] = st.checkbox(
                    "ä½¿ç”¨è‡ªå®šä¹‰åœç”¨è¯", value=True
                )
            with col2:
                self.config['bertopic_params']['expert_keyword_extraction']['pos_language_detection'] = st.checkbox(
                    "è‡ªåŠ¨è¯­è¨€æ£€æµ‹", value=True
                )
        
        with st.expander("ğŸ“ˆ UMAPé™ç»´å‚æ•°"):
            col1, col2 = st.columns(2)
            with col1:
                self.config['bertopic_params']['umap_params']['n_neighbors'] = st.slider(
                    "é‚»å±…æ•°é‡", 5, 50, 15
                )
                self.config['bertopic_params']['umap_params']['n_components'] = st.slider(
                    "é™ç»´ç»´åº¦", 2, 10, 5
                )
            with col2:
                self.config['bertopic_params']['umap_params']['min_dist'] = st.slider(
                    "æœ€å°è·ç¦»", 0.0, 1.0, 0.0, 0.1
                )
                self.config['bertopic_params']['umap_params']['metric'] = st.selectbox(
                    "è·ç¦»åº¦é‡", ['cosine', 'euclidean', 'manhattan'], index=0
                )
        
        with st.expander("ğŸ” HDBSCANèšç±»å‚æ•°"):
            col1, col2 = st.columns(2)
            with col1:
                self.config['bertopic_params']['hdbscan_params']['min_cluster_size'] = st.slider(
                    "æœ€å°èšç±»å¤§å°", 5, 100, 15
                )
                self.config['bertopic_params']['hdbscan_params']['min_samples'] = st.slider(
                    "æœ€å°æ ·æœ¬æ•°", 1, 20, 5
                )
            with col2:
                self.config['bertopic_params']['hdbscan_params']['metric'] = st.selectbox(
                    "èšç±»è·ç¦»", ['euclidean', 'manhattan'], index=0
                )
                self.config['bertopic_params']['hdbscan_params']['cluster_selection_method'] = st.selectbox(
                    "èšç±»é€‰æ‹©æ–¹æ³•", ['eom', 'leaf'], index=0
                )
        
        # åˆ†æåŠŸèƒ½å¼€å…³
        st.markdown("---")
        st.subheader("ğŸ”¬ åˆ†æåŠŸèƒ½")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            self.config['analysis']['time_analysis']['enable'] = st.checkbox(
                "æ—¶é—´æ¼”åŒ–åˆ†æ", value=True
            )
        with col2:
            self.config['analysis']['source_analysis']['enable'] = st.checkbox(
                "æ¥æºå¯¹æ¯”åˆ†æ", value=True
            )
        with col3:
            self.config['analysis']['frame_analysis']['enable'] = st.checkbox(
                "æ¡†æ¶åˆ†æ", value=True
            )
    
    def _render_analysis_runner(self):
        """æ¸²æŸ“åˆ†æè¿è¡Œç•Œé¢"""
        st.markdown('<div class="module-header">ğŸš€ è¿è¡Œåˆ†æ</div>', unsafe_allow_html=True)
        
        # æ£€æŸ¥å‰ç½®æ¡ä»¶
        can_run = self._check_prerequisites()
        
        if not can_run:
            st.warning("âš ï¸ è¯·å…ˆå®Œæˆæ•°æ®ä¸Šä¼ å’Œå‚æ•°é…ç½®")
            return
        
        # æ˜¾ç¤ºå½“å‰é…ç½®æ‘˜è¦
        with st.expander("ğŸ“‹ å½“å‰é…ç½®æ‘˜è¦"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("**åŸºç¡€å‚æ•°:**")
                st.write(f"- æ–‡æœ¬åˆ—: {self.config['data_processing']['text_column']}")
                st.write(f"- æœ€å°ä¸»é¢˜å¤§å°: {self.config['bertopic_params']['min_topic_size']}")
                st.write(f"- ä¸»é¢˜æ•°é‡: {self.config['bertopic_params']['nr_topics']}")
            with col2:
                st.write("**å¯ç”¨åŠŸèƒ½:**")
                st.write(f"- è¯æ€§æ ‡æ³¨: {'âœ…' if self.config['bertopic_params']['expert_keyword_extraction']['enable_pos_patterns'] else 'âŒ'}")
                st.write(f"- æ—¶é—´åˆ†æ: {'âœ…' if self.config['analysis']['time_analysis']['enable'] else 'âŒ'}")
                st.write(f"- è·¨è¯­è¨€åˆ†æ: âœ…")
        
        # è¿è¡ŒæŒ‰é’®
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
                self._run_analysis()
    
    def _render_results_viewer(self):
        """æ¸²æŸ“ç»“æœæŸ¥çœ‹ç•Œé¢"""
        st.markdown('<div class="module-header">ğŸ“Š åˆ†æç»“æœæŸ¥çœ‹</div>', unsafe_allow_html=True)
        
        if st.session_state.analysis_results is None:
            st.info("ğŸ” è¿˜æ²¡æœ‰åˆ†æç»“æœï¼Œè¯·å…ˆè¿è¡Œåˆ†æ")
            return
        
        results = st.session_state.analysis_results
        
        # ç»“æœæ‘˜è¦
        st.subheader("ğŸ“ˆ åˆ†ææ‘˜è¦")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("è¯†åˆ«ä¸»é¢˜æ•°", results.get('n_topics', 0))
        with col2:
            st.metric("åˆ†ææ–‡æ¡£æ•°", results.get('n_documents', 0))
        with col3:
            st.metric("å¤„ç†æ—¶é—´", f"{results.get('elapsed_time', 0):.1f}ç§’")
        with col4:
            st.metric("ç”Ÿæˆæ–‡ä»¶æ•°", len(results.get('generated_files', [])))
        
        # ç»“æœæ–‡ä»¶ä¸‹è½½
        st.markdown("---")
        st.subheader("ğŸ“¥ ç»“æœæ–‡ä»¶ä¸‹è½½")
        
        if results.get('generated_files'):
            # åˆ›å»ºä¸‹è½½åŒ…
            zip_buffer = self._create_results_zip(results['generated_files'])
            
            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰ç»“æœ",
                    data=zip_buffer,
                    file_name=f"bertopic_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                    mime="application/zip"
                )
            
            with col2:
                st.info(f"åŒ…å« {len(results['generated_files'])} ä¸ªç»“æœæ–‡ä»¶")
        
        # åœ¨çº¿é¢„è§ˆ
        st.markdown("---")
        st.subheader("ğŸ‘ï¸ ç»“æœé¢„è§ˆ")
        
        # æ˜¾ç¤ºä¸»é¢˜æ‘˜è¦è¡¨æ ¼
        if 'topics_summary' in results:
            st.subheader("ğŸ“Š ä¸»é¢˜æ‘˜è¦")
            st.dataframe(results['topics_summary'])
        
        # æ˜¾ç¤ºå›¾è¡¨
        if 'charts' in results:
            for chart_name, chart_path in results['charts'].items():
                if chart_path and Path(chart_path).exists():
                    st.subheader(f"ğŸ“ˆ {chart_name}")
                    if chart_path.endswith('.png'):
                        st.image(chart_path)
                    elif chart_path.endswith('.html'):
                        with open(chart_path, 'r', encoding='utf-8') as f:
                            st.components.v1.html(f.read(), height=500)
    
    def _save_uploaded_file(self, uploaded_file, file_key: str) -> str:
        """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
        temp_dir = Path("temp")
        temp_dir.mkdir(exist_ok=True)
        
        file_path = temp_dir / f"{file_key}.xlsx"
        
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        return str(file_path)
    
    def _validate_uploaded_data(self):
        """éªŒè¯ä¸Šä¼ çš„æ•°æ®"""
        all_valid = True
        
        for file_key, file_path in st.session_state.uploaded_files.items():
            try:
                df = pd.read_excel(file_path)
                text_column = self.config['data_processing']['text_column']
                
                if text_column not in df.columns:
                    st.error(f"âŒ {file_key}: æœªæ‰¾åˆ°æ–‡æœ¬åˆ— '{text_column}'")
                    all_valid = False
                else:
                    valid_texts = df[text_column].dropna()
                    st.success(f"âœ… {file_key}: {len(valid_texts)} ä¸ªæœ‰æ•ˆæ–‡æœ¬")
                    
            except Exception as e:
                st.error(f"âŒ {file_key}: æ–‡ä»¶éªŒè¯å¤±è´¥ - {e}")
                all_valid = False
        
        if all_valid and len(st.session_state.uploaded_files) >= 2:
            st.success("ğŸ‰ æ‰€æœ‰æ•°æ®æ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹åˆ†æï¼")
    
    def _check_prerequisites(self) -> bool:
        """æ£€æŸ¥è¿è¡Œåˆ†æçš„å‰ç½®æ¡ä»¶"""
        if len(st.session_state.uploaded_files) < 2:
            return False
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
        for file_path in st.session_state.uploaded_files.values():
            if not Path(file_path).exists():
                return False
        
        return True
    
    def _run_analysis(self):
        """è¿è¡Œåˆ†æ"""
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # æ›´æ–°é…ç½®ä¸­çš„æ–‡ä»¶è·¯å¾„
            self.config['data_paths']['media_data'] = st.session_state.uploaded_files['media_data']
            self.config['data_paths']['social_media_data'] = st.session_state.uploaded_files['social_media_data']
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path(self.config['results_paths']['output_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)
            
            status_text.text("ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...")
            progress_bar.progress(20)
            
            # åŠ è½½æ•°æ®
            data_loader = DataLoader(self.config)
            documents, metadata_df = data_loader.load_and_prepare_data()
            
            status_text.text("ğŸ¤– æ­£åœ¨è®­ç»ƒæ¨¡å‹...")
            progress_bar.progress(50)
            
            # è®­ç»ƒæ¨¡å‹
            analyzer = TopicAnalyzer(self.config)
            topic_model, topics = analyzer.train_bertopic_model(documents)
            
            status_text.text("ğŸ“Š æ­£åœ¨ç”Ÿæˆç»“æœ...")
            progress_bar.progress(80)
            
            # ç”Ÿæˆå¢å¼ºç»“æœ
            enhanced_topics = analyzer.expert_extractor.enhance_topic_representation(
                topic_model, documents
            )
            
            analyzer.generate_enhanced_results(
                topic_model=topic_model,
                documents=documents,
                topics=topics,
                metadata_df=metadata_df,
                enhanced_topics=enhanced_topics
            )
            
            status_text.text("âœ… åˆ†æå®Œæˆï¼")
            progress_bar.progress(100)
            
            # ä¿å­˜ç»“æœåˆ°session state
            results = self._collect_results(topic_model, documents, output_dir)
            st.session_state.analysis_results = results
            
            st.success("ğŸ‰ åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ç»“æœæ ‡ç­¾é¡µã€‚")
            
        except Exception as e:
            st.error(f"âŒ åˆ†æå¤±è´¥: {e}")
            st.exception(e)
    
    def _collect_results(self, topic_model, documents, output_dir: Path) -> dict:
        """æ”¶é›†åˆ†æç»“æœ"""
        results = {
            'n_topics': len(topic_model.get_topic_info()) - 1,
            'n_documents': len(documents),
            'elapsed_time': 0,  # TODO: å®é™…è®¡ç®—æ—¶é—´
            'generated_files': [],
            'charts': {},
            'topics_summary': None
        }
        
        # æ”¶é›†ç”Ÿæˆçš„æ–‡ä»¶
        for file_path in output_dir.glob("**/*"):
            if file_path.is_file():
                results['generated_files'].append(str(file_path))
                
                # åˆ†ç±»å›¾è¡¨æ–‡ä»¶
                if file_path.suffix in ['.png', '.html', '.pdf']:
                    results['charts'][file_path.stem] = str(file_path)
        
        # è¯»å–ä¸»é¢˜æ‘˜è¦
        summary_files = list(output_dir.glob("*summary*.csv"))
        if summary_files:
            try:
                results['topics_summary'] = pd.read_csv(summary_files[0])
            except:
                pass
        
        return results
    
    def _create_results_zip(self, file_paths: list) -> bytes:
        """åˆ›å»ºç»“æœæ–‡ä»¶çš„zipåŒ…"""
        zip_buffer = BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for file_path in file_paths:
                if Path(file_path).exists():
                    zip_file.write(file_path, Path(file_path).name)
        
        zip_buffer.seek(0)
        return zip_buffer.getvalue()
    
    def _download_config_template(self):
        """ä¸‹è½½é…ç½®æ¨¡æ¿"""
        config_yaml = yaml.dump(self.config, default_flow_style=False, allow_unicode=True)
        st.sidebar.download_button(
            label="ğŸ“„ config.yaml",
            data=config_yaml,
            file_name="config_template.yaml",
            mime="text/yaml"
        )


def main():
    """ä¸»å‡½æ•°"""
    try:
        web_ui = BERTopicWebUI()
        web_ui.render_main_page()
    except Exception as e:
        st.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
        st.exception(e)


if __name__ == "__main__":
    main()
