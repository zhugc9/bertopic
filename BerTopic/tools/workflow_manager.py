"""
BERTopicå·¥ä½œæµç®¡ç†å™¨
==================
ç®€åŒ–çš„å·¥ä½œæµç¨‹ç®¡ç†
"""

import yaml
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime


class WorkflowManager:
    """ç®€åŒ–çš„å·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, config_path: str):
        """åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨"""
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.results_dir = Path(self.config['results_paths']['output_dir'])
        self.results_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.documents = None
        self.metadata_df = None
        self.topic_model = None
        self.topics = None
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = self.results_dir / 'bertopic_analysis.log'
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger(__name__)
    
    def load_data(self) -> bool:
        """åŠ è½½æ•°æ®"""
        self.logger.info("ğŸ“ å¼€å§‹åŠ è½½æ•°æ®...")
        
        try:
            from topic_analyzer.data_loader import DataLoader
            
            data_loader = DataLoader(self.config)
            self.documents, self.metadata_df = data_loader.load_and_prepare_data()
            
            self.logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼š{len(self.documents)} ä¸ªæ–‡æ¡£")
            
            if self.metadata_df is not None:
                self.logger.info(f"  å…ƒæ•°æ®ç»´åº¦: {self.metadata_df.shape}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def run_hyperparameter_optimization(self) -> Optional[Dict]:
        """è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–"""
        opt_config = self.config.get('hyperparameter_optimization', {})
        
        if not opt_config.get('enable', False):
            self.logger.info("â­ï¸ è¶…å‚æ•°ä¼˜åŒ–å·²ç¦ç”¨ï¼Œè·³è¿‡")
            return None
        
        self.logger.info("ğŸ” å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–...")
        
        try:
            from topic_analyzer.model import TopicAnalyzer
            
            analyzer = TopicAnalyzer(self.config)
            optimization_results = analyzer.optimize_hyperparameters(self.documents)
            
            if optimization_results:
                self.logger.info("âœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ")
                return optimization_results
            else:
                self.logger.warning("âš ï¸ è¶…å‚æ•°ä¼˜åŒ–æœªè¿”å›ç»“æœ")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return None
    
    def train_topic_model(self, use_optimized_params: bool = False) -> bool:
        """è®­ç»ƒä¸»é¢˜æ¨¡å‹"""
        self.logger.info("ğŸ¤– å¼€å§‹è®­ç»ƒä¸»é¢˜æ¨¡å‹...")
        
        try:
            from topic_analyzer.model import TopicAnalyzer
            
            analyzer = TopicAnalyzer(self.config)
            
            if use_optimized_params:
                self.topic_model, self.topics = analyzer.train_with_optimized_parameters(self.documents)
                self.logger.info("  ä½¿ç”¨ä¼˜åŒ–å‚æ•°è®­ç»ƒ")
            else:
                self.topic_model, self.topics = analyzer.train_bertopic_model(self.documents)
                self.logger.info("  ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ")
            
            # æ¨¡å‹ç»Ÿè®¡
            topic_info = self.topic_model.get_topic_info()
            n_topics = len(topic_info) - 1  # æ’é™¤å™ªå£°ä¸»é¢˜
            
            self.logger.info(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
            self.logger.info(f"  å‘ç°ä¸»é¢˜æ•°: {n_topics}")
            self.logger.info(f"  æ€»æ–‡æ¡£æ•°: {len(self.documents)}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def generate_results(self) -> bool:
        """ç”Ÿæˆåˆ†æç»“æœ"""
        if not self.topic_model:
            self.logger.error("æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•ç”Ÿæˆç»“æœ")
            return False
        
        self.logger.info("ğŸ“Š ç”Ÿæˆåˆ†æç»“æœ...")
        
        try:
            from topic_analyzer.model import TopicAnalyzer
            
            analyzer = TopicAnalyzer(self.config)
            
            # 1. åŸºç¡€ç»“æœ
            self.logger.info("  ç”ŸæˆåŸºç¡€ç»“æœ...")
            analyzer.generate_results(
                self.topic_model, 
                self.documents, 
                self.topics, 
                self.metadata_df
            )
            
            # 2. é«˜çº§å¯è§†åŒ–
            viz_config = self.config.get('visualization', {}).get('sota_charts', {})
            if viz_config.get('enable', True):
                self.logger.info("  ç”Ÿæˆé«˜çº§å¯è§†åŒ–...")
                charts = analyzer.generate_sota_visualizations(
                    self.topic_model,
                    self.documents, 
                    self.topics,
                    self.metadata_df
                )
                
                if charts:
                    self.logger.info(f"  âœ“ ç”Ÿæˆå›¾è¡¨: {len(charts)} ä¸ª")
                else:
                    self.logger.warning("  âš  å›¾è¡¨ç”Ÿæˆå¤±è´¥")
            else:
                self.logger.info("  â­ï¸ é«˜çº§å¯è§†åŒ–å·²ç¦ç”¨")
            
            self.logger.info("âœ… åˆ†æç»“æœç”Ÿæˆå®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ç»“æœç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def run_complete_analysis(self, optimize_params: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹å®Œæ•´ä¸»é¢˜åˆ†ææµç¨‹...")
        
        # 1. åŠ è½½æ•°æ®
        if not self.load_data():
            return False
        
        # 2. è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
        optimization_results = None
        if optimize_params:
            optimization_results = self.run_hyperparameter_optimization()
        
        # 3. è®­ç»ƒæ¨¡å‹
        use_optimized = optimization_results is not None
        if not self.train_topic_model(use_optimized_params=use_optimized):
            return False
        
        # 4. ç”Ÿæˆç»“æœ
        if not self.generate_results():
            return False
        
        self.logger.info("ğŸ‰ å®Œæ•´åˆ†ææµç¨‹æˆåŠŸå®Œæˆï¼")
        return True
