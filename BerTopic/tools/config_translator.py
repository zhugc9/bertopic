"""
é…ç½®ç¿»è¯‘å™¨
===========
å°†ç”¨æˆ·å‹å¥½çš„config.yamlè½¬æ¢ä¸ºæŠ€æœ¯å‚æ•°
"""

import yaml
from pathlib import Path
from typing import Dict, Any
import logging

logger = logging.getLogger(__name__)


class ConfigTranslator:
    """é…ç½®ç¿»è¯‘å™¨ - å°†ç”¨æˆ·é…ç½®è½¬æ¢ä¸ºæŠ€æœ¯å‚æ•°"""
    
    def __init__(self, user_config_path: str):
        """
        åˆå§‹åŒ–é…ç½®ç¿»è¯‘å™¨
        
        Args:
            user_config_path: ç”¨æˆ·é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.user_config_path = Path(user_config_path)
        self.user_config = self._load_user_config()
    
    def _load_user_config(self) -> Dict[str, Any]:
        """åŠ è½½ç”¨æˆ·é…ç½®"""
        if not self.user_config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.user_config_path}")
        
        with open(self.user_config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        logger.info("âœ… ç”¨æˆ·é…ç½®åŠ è½½æˆåŠŸ")
        return config
    
    def translate_to_technical_config(self) -> Dict[str, Any]:
        """
        å°†ç”¨æˆ·å‹å¥½é…ç½®è½¬æ¢ä¸ºæŠ€æœ¯é…ç½®
        
        Returns:
            æŠ€æœ¯é…ç½®å­—å…¸
        """
        logger.info("ğŸ”„ å¼€å§‹é…ç½®è½¬æ¢...")
        
        # åŸºç¡€æŠ€æœ¯é…ç½®æ¡†æ¶
        tech_config = {
            'data_paths': self._translate_data_paths(),
            'results_paths': self._translate_results_paths(),
            'bertopic_params': self._translate_bertopic_params(),
            'visualization': self._translate_visualization(),
            'analysis': self._translate_analysis(),
            'hyperparameter_optimization': self._translate_optimization(),
            'system': self._translate_system(),
            'data_processing': self._translate_data_processing()
        }
        
        logger.info("âœ… é…ç½®è½¬æ¢å®Œæˆ")
        return tech_config
    
    def _translate_data_paths(self) -> Dict[str, Any]:
        """è½¬æ¢æ•°æ®è·¯å¾„é…ç½®"""
        # æ–°é…ç½®ç»“æ„
        user_paths = self.user_config.get('data_files', {})
        
        return {
            'media_data': user_paths.get('traditional_media'),
            'social_media_data': user_paths.get('social_media')
        }
    
    def _translate_results_paths(self) -> Dict[str, Any]:
        """è½¬æ¢ç»“æœè·¯å¾„é…ç½®"""
        output_dir = self.user_config.get('output_settings', {}).get('results_folder', 'results')
        
        return {
            'output_dir': output_dir,
            'model_dir': f"{output_dir}/trained_model",
            'summary_file': f"{output_dir}/topics_summary.csv",
            'summary_enhanced': f"{output_dir}/topics_summary_enhanced.csv",
            'cross_lingual_file': f"{output_dir}/cross_lingual_composition.csv",
            'evolution_file': f"{output_dir}/dynamic_evolution_analysis.csv",
            'viz_file': f"{output_dir}/topic_visualization.html",
            'source_analysis': f"{output_dir}/topic_by_source.html",
            'timeline_analysis': f"{output_dir}/topics_over_time.html",
            'frame_heatmap': f"{output_dir}/topic_frame_heatmap.html"
        }
    
    def _translate_bertopic_params(self) -> Dict[str, Any]:
        """è½¬æ¢BERTopicå‚æ•°"""
        # æ–°é…ç½®ç»“æ„
        topic_config = self.user_config.get('topic_settings', {})
        
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„ç²¾åº¦çº§åˆ«è®¾ç½®å‚æ•°
        advanced = topic_config.get('advanced', {})
        precision = advanced.get('keyword_extraction', 'standard')
        if precision == 'basic':
            ngram_range = [1, 2]
            max_features = 3000
        elif precision == 'enhanced':
            ngram_range = [1, 4]
            max_features = 10000
        else:  # standard
            ngram_range = [1, 3]
            max_features = 5000
        
        # æ ¹æ®è¯­è¨€æ¨¡å¼é€‰æ‹©embeddingæ¨¡å‹
        language_mode = topic_config.get('text_language', 'chinese')
        if language_mode == 'chinese':
            embedding_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        elif language_mode == 'english':
            embedding_model = "sentence-transformers/all-MiniLM-L6-v2"
        elif language_mode == 'multilingual':
            embedding_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        else:  # é»˜è®¤ä¸­æ–‡
            embedding_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        
        # è·å–å‚æ•°ï¼ˆè°ƒå‚æ¨¡å¼ç”¨é»˜è®¤å€¼ï¼Œåˆ†ææ¨¡å¼ç”¨é€‰ä¸­çš„å‚æ•°ï¼‰
        if self.is_tuning_mode():
            params = self._get_default_parameters()
        else:
            params = self.get_selected_parameters()
        
        advanced = topic_config.get('advanced', {})
        
        return {
            'language': language_mode,
            'embedding_model': embedding_model,
            'min_topic_size': params.get('min_topic_size', topic_config.get('min_documents_per_topic', 15)),
            'nr_topics': topic_config.get('expected_topics', 'auto'),
            'n_gram_range': advanced.get('ngram_range', ngram_range),
            
            # å¤šè¯­è¨€é¢„å¤„ç†é…ç½®
            'expert_keyword_extraction': {
                'enable_pos_patterns': True,
                'enable_multilingual_preprocessing': True,
                'pos_patterns': {
                    'zh': '<n.*|a.*>*<n.*>+',
                    'en': '<JJ.*>*<NN.*>+',
                    'ru': '<A.*>*<N.*>+'
                },
                'custom_stopwords_path': 'stopwords/politics_stopwords.txt',
                'use_custom_stopwords': True,
                'pos_language_detection': True
            },
            
            # UMAPå‚æ•°
            'umap_params': {
                'n_neighbors': params.get('n_neighbors', 15),
                'n_components': params.get('n_components', 5),
                'min_dist': advanced.get('min_dist', 0.0),
                'metric': 'cosine',
                'random_state': 42
            },
            
            # HDBSCANå‚æ•°
            'hdbscan_params': {
                'min_cluster_size': params.get('min_cluster_size', 15),
                'min_samples': params.get('min_samples', 5),
                'metric': 'euclidean',
                'cluster_selection_method': 'eom',
                'prediction_data': True
            }
        }
    
    def _translate_visualization(self) -> Dict[str, Any]:
        """è½¬æ¢å¯è§†åŒ–é…ç½®"""
        viz_config = self.user_config.get('visualization', {})
        
        # æ ¹æ®å›¾è¡¨è´¨é‡è®¾ç½®DPI
        quality = viz_config.get('chart_quality', 'high')
        if quality == 'standard':
            dpi = 150
        elif quality == 'publication':
            dpi = 600
        else:  # high
            dpi = 300
        
        return {
            'figsize': [viz_config.get('figure_width', 12), viz_config.get('figure_height', 8)],
            'dpi': viz_config.get('dpi', dpi),
            'style': 'matplotlib',
            'color_scheme': 'viridis',
            'save_format': 'png',
            
            'sota_charts': {
                'enable': self.user_config.get('analysis_mode', {}).get('enable_academic_visualizations', True),
                'high_dpi': dpi,
                'formats': viz_config.get('output_formats', ['png', 'svg']),
                'font_family': 'Times New Roman' if viz_config.get('font_style') == 'serif' else 'Arial',
                'color_palette': viz_config.get('color_theme', 'academic'),
                'enable_annotations': True,
                'annotation_examples': []
            }
        }
    
    def _translate_analysis(self) -> Dict[str, Any]:
        """è½¬æ¢åˆ†æåŠŸèƒ½é…ç½®"""
        temporal = self.user_config.get('temporal_analysis', {})
        source = self.user_config.get('source_analysis', {})
        frame = self.user_config.get('frame_analysis', {})
        
        return {
            'time_analysis': {
                'enable': temporal.get('enable', True),
                'time_column': temporal.get('date_column', 'æ—¥æœŸ'),
                'bins': temporal.get('time_periods', 10)
            },
            
            'source_analysis': {
                'enable': source.get('enable', True),
                'source_column': source.get('source_column', 'Source')
            },
            
            'frame_analysis': {
                'enable': frame.get('enable', True),
                'threshold': frame.get('frame_threshold', 0.1)
            }
        }
    
    def _translate_optimization(self) -> Dict[str, Any]:
        """è½¬æ¢è¶…å‚æ•°ä¼˜åŒ–é…ç½®"""
        enable_opt = self.is_tuning_mode()
        tuning_config = self.user_config.get('tuning_settings', {})
        search_ranges = tuning_config.get('search_ranges', {})
        
        return {
            'enable': enable_opt,
            'n_trials': tuning_config.get('optimization_trials', 100),
            
            'search_space': {
                'n_neighbors': search_ranges.get('n_neighbors', [5, 50]),
                'n_components': search_ranges.get('n_components', [2, 10]),
                'min_dist': [0.0, 0.5],
                'min_cluster_size': search_ranges.get('min_cluster_size', [5, 100]),
                'min_samples': search_ranges.get('min_samples', [1, 15]),
                'ngram_range': [1, 4],
                'max_features': [1000, 10000]
            },
            
            'coherence_type': 'c_v',
            'save_top_n': tuning_config.get('save_top_candidates', 5),
            'auto_apply_best': False,
            'show_progress': True,
            'save_intermediate': True,
            'study_name': 'auto'
        }
    
    def _translate_system(self) -> Dict[str, Any]:
        """è½¬æ¢ç³»ç»Ÿé…ç½®"""
        system_config = self.user_config.get('advanced_settings', {}).get('system', {})
        
        return {
            'random_seed': system_config.get('random_seed', 42),
            'verbose': system_config.get('verbose', True),
            'save_intermediate': False,
            'use_gpu': False
        }
    
    def _translate_data_processing(self) -> Dict[str, Any]:
        """è½¬æ¢æ•°æ®å¤„ç†é…ç½®"""
        return {
            'text_column': 'Unit_Text',
            'merge_strategy': 'concat',
            'metadata_columns': [
                'åºå·', 'æ—¥æœŸ', 'æ ‡é¢˜', 'é“¾æ¥', 'Tokenæ•°', 'text', 'tokenæ•°',
                'Unit_ID', 'Source', 'Macro_Chunk_ID', 'speaker', 'Unit_Text',
                'seed_sentence', 'expansion_logic', 'Unit_Hash', 'processing_status',
                'Incident', 'Valence',
                
                # Frameåˆ†æåˆ—
                'Frame_ProblemDefinition', 'Frame_ProblemDefinition_Present',
                'Frame_ResponsibilityAttribution', 'Frame_ResponsibilityAttribution_Present',
                'Frame_MoralEvaluation', 'Frame_MoralEvaluation_Present',
                'Frame_SolutionRecommendation', 'Frame_TreatmentRecommendation_Present',
                'Frame_ActionStatement', 'Frame_ConflictAttribution_Present',
                'Frame_CausalExplanation', 'Frame_CausalInterpretation_Present',
                
                # åˆ†æç»´åº¦åˆ—
                'Evidence_Type', 'Attribution_Level', 'Temporal_Focus',
                'Primary_Actor_Type', 'Geographic_Scope',
                'Relationship_Model_Definition', 'Discourse_Type'
            ]
        }
    
    def get_analysis_mode(self) -> str:
        """è·å–åˆ†ææ¨¡å¼"""
        # æ–°é…ç½®ç»“æ„
        mode = self.user_config.get('analysis_mode', 'analyze')
        
        # ä¸¤é˜¶æ®µæ¨¡å¼æ˜ å°„
        if mode == 'tune':
            return 'tune'  # è°ƒå‚æ¨¡å¼
        else:
            return 'analyze'  # åˆ†ææ¨¡å¼
    
    def is_tuning_mode(self) -> bool:
        """æ˜¯å¦ä¸ºè°ƒå‚æ¨¡å¼"""
        return self.get_analysis_mode() == 'tune'
    
    def get_selected_parameters(self) -> Dict[str, Any]:
        """è·å–é€‰ä¸­çš„å€™é€‰å‚æ•°"""
        # æ–°é…ç½®ç»“æ„
        candidate_config = self.user_config.get('parameter_selection', {})
        
        if candidate_config.get('manual_override', {}).get('enable', False):
            # ä½¿ç”¨æ‰‹åŠ¨å‚æ•°
            manual = candidate_config['manual_override']
            return {
                'min_topic_size': manual.get('min_documents_per_topic', 15),
                'n_neighbors': 15,  # é»˜è®¤å€¼
                'n_components': 5,  # é»˜è®¤å€¼
                'min_cluster_size': manual.get('min_documents_per_topic', 15),
                'min_samples': 5  # é»˜è®¤å€¼
            }
        else:
            # ä½¿ç”¨å€™é€‰å‚æ•°
            selected_num = candidate_config.get('use_candidate', 1)
            candidates = candidate_config.get('candidates', {})
            candidate_key = f'candidate_{selected_num}'
            
            if candidate_key in candidates:
                candidate = candidates[candidate_key]
                return {
                    'min_topic_size': candidate.get('min_topic_size', 15),
                    'n_neighbors': candidate.get('n_neighbors', 15),
                    'n_components': candidate.get('n_components', 5),
                    'min_cluster_size': candidate.get('min_cluster_size', 15),
                    'min_samples': candidate.get('min_samples', 5)
                }
            else:
                # å›é€€åˆ°é»˜è®¤å‚æ•°
                return self._get_default_parameters()
    
    def _get_default_parameters(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤å‚æ•°"""
        topic_config = self.user_config.get('topic_parameters', {})
        advanced = topic_config.get('advanced', {})
        
        return {
            'min_topic_size': topic_config.get('min_topic_size', 15),
            'n_neighbors': advanced.get('n_neighbors', 15),
            'n_components': advanced.get('n_components', 5),
            'min_cluster_size': advanced.get('min_cluster_size', 15),
            'min_samples': advanced.get('min_samples', 5)
        }
    
    def save_technical_config(self, output_path: str = None) -> str:
        """
        ä¿å­˜æŠ€æœ¯é…ç½®åˆ°æ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = self.user_config_path.parent / 'config_technical.yaml'
        
        tech_config = self.translate_to_technical_config()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(tech_config, f, default_flow_style=False, allow_unicode=True, indent=2)
        
        logger.info(f"âœ… æŠ€æœ¯é…ç½®å·²ä¿å­˜: {output_path}")
        return str(output_path)


def translate_config(user_config_path: str) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šç›´æ¥è½¬æ¢é…ç½®
    
    Args:
        user_config_path: ç”¨æˆ·é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        æŠ€æœ¯é…ç½®å­—å…¸
    """
    translator = ConfigTranslator(user_config_path)
    return translator.translate_to_technical_config()


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®è½¬æ¢
    translator = ConfigTranslator('config.yaml')
    tech_config = translator.translate_to_technical_config()
    translator.save_technical_config('config_technical.yaml')
    
    print("ğŸ‰ é…ç½®è½¬æ¢å®Œæˆï¼")
    print(f"åˆ†ææ¨¡å¼: {translator.get_analysis_mode()}")
