"""
è·¨è¯­è¨€ä¸»é¢˜æˆåˆ†åˆ†ææ¨¡å—
====================
åˆ†ææ¯ä¸ªä¸»é¢˜å†…éƒ¨çš„è¯­è¨€æ„æˆå’Œè·¨è¯­è¨€ç‰¹æ€§
"""

import pandas as pd
import numpy as np
import logging
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import List, Dict, Any, Tuple
from langdetect import detect
import re
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)


class CrossLingualAnalyzer:
    """è·¨è¯­è¨€ä¸»é¢˜æˆåˆ†åˆ†æå™¨ - SOTA & KISSå®ç°"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–è·¨è¯­è¨€åˆ†æå™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.results_paths = config['results_paths']
        
        # è¯­è¨€æ£€æµ‹å’Œåˆ†ç±»è§„åˆ™
        self.language_patterns = {
            'zh': re.compile(r'[\u4e00-\u9fff]'),      # ä¸­æ–‡å­—ç¬¦
            'ru': re.compile(r'[\u0400-\u04ff]'),      # ä¿„æ–‡å­—ç¬¦  
            'en': re.compile(r'^[a-zA-Z\s\d\.,!?\-\'\"]*$')  # è‹±æ–‡å­—ç¬¦ï¼ˆç›¸å¯¹å®½æ¾ï¼‰
        }
        
    def detect_document_language(self, text: str) -> str:
        """
        æ£€æµ‹å•ä¸ªæ–‡æ¡£çš„ä¸»è¦è¯­è¨€
        
        Args:
            text: æ–‡æ¡£æ–‡æœ¬
            
        Returns:
            è¯­è¨€ä»£ç  ('zh', 'ru', 'en', 'mixed', 'unknown')
        """
        if not text or len(text.strip()) < 3:
            return 'unknown'
        
        text = text.strip()
        
        # ç»Ÿè®¡å„è¯­è¨€å­—ç¬¦æ•°é‡
        zh_chars = len(self.language_patterns['zh'].findall(text))
        ru_chars = len(self.language_patterns['ru'].findall(text))
        
        # æ€»å­—ç¬¦æ•°ï¼ˆæ’é™¤ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        total_chars = len(re.sub(r'[\s\d\.,!?\-\'\"()ã€ã€‘ã€Šã€‹""''ï¼›ï¼š]', '', text))
        
        if total_chars == 0:
            return 'unknown'
        
        # è®¡ç®—å„è¯­è¨€å­—ç¬¦æ¯”ä¾‹
        zh_ratio = zh_chars / total_chars
        ru_ratio = ru_chars / total_chars
        other_ratio = 1 - zh_ratio - ru_ratio
        
        # åˆ¤æ–­ä¸»è¦è¯­è¨€
        if zh_ratio > 0.3:
            if ru_ratio > 0.1 or other_ratio > 0.3:
                return 'mixed'  # æ··åˆè¯­è¨€
            return 'zh'
        elif ru_ratio > 0.3:
            if zh_ratio > 0.1 or other_ratio > 0.3:
                return 'mixed'
            return 'ru'
        elif other_ratio > 0.8:
            return 'en'  # å‡è®¾å…¶ä»–å­—ç¬¦ä¸»è¦æ˜¯è‹±æ–‡
        else:
            return 'mixed'
    
    def analyze_document_languages(self, documents: List[str]) -> List[str]:
        """
        æ‰¹é‡åˆ†ææ–‡æ¡£è¯­è¨€
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            è¯­è¨€æ ‡ç­¾åˆ—è¡¨
        """
        logger.info("ğŸŒ åˆ†ææ–‡æ¡£è¯­è¨€ç»„æˆ...")
        
        languages = []
        language_counts = {'zh': 0, 'ru': 0, 'en': 0, 'mixed': 0, 'unknown': 0}
        
        for i, doc in enumerate(documents):
            lang = self.detect_document_language(doc)
            languages.append(lang)
            language_counts[lang] += 1
            
            if i % 1000 == 0 and i > 0:
                logger.info(f"  â†’ å·²å¤„ç† {i}/{len(documents)} ä¸ªæ–‡æ¡£")
        
        # ç»Ÿè®¡ç»“æœ
        total = len(documents)
        logger.info("  âœ“ è¯­è¨€åˆ†å¸ƒç»Ÿè®¡:")
        for lang, count in language_counts.items():
            percentage = (count / total) * 100
            lang_name = {'zh': 'ä¸­æ–‡', 'ru': 'ä¿„æ–‡', 'en': 'è‹±æ–‡', 'mixed': 'æ··åˆ', 'unknown': 'æœªçŸ¥'}[lang]
            logger.info(f"    {lang_name}: {count} ({percentage:.1f}%)")
        
        return languages
    
    def analyze_topic_language_composition(self,
                                         topics: List[int],
                                         document_languages: List[str]) -> pd.DataFrame:
        """
        åˆ†ææ¯ä¸ªä¸»é¢˜çš„è¯­è¨€æ„æˆ
        
        Args:
            topics: ä¸»é¢˜æ ‡ç­¾åˆ—è¡¨
            document_languages: æ–‡æ¡£è¯­è¨€åˆ—è¡¨
            
        Returns:
            ä¸»é¢˜è¯­è¨€æ„æˆDataFrame
        """
        logger.info("ğŸ“Š åˆ†æä¸»é¢˜è¯­è¨€æ„æˆ...")
        
        # åˆ›å»ºæ•°æ®æ¡†
        df = pd.DataFrame({
            'topic': topics,
            'language': document_languages
        })
        
        # æ’é™¤ç¦»ç¾¤ç‚¹
        df = df[df['topic'] != -1]
        
        if df.empty:
            logger.warning("  âš  æ²¡æœ‰æœ‰æ•ˆä¸»é¢˜æ•°æ®")
            return pd.DataFrame()
        
        # è®¡ç®—æ¯ä¸ªä¸»é¢˜çš„è¯­è¨€æ„æˆ
        composition_data = []
        
        for topic_id in sorted(df['topic'].unique()):
            topic_docs = df[df['topic'] == topic_id]
            total_docs = len(topic_docs)
            
            if total_docs == 0:
                continue
            
            # ç»Ÿè®¡å„è¯­è¨€æ–‡æ¡£æ•°é‡
            lang_counts = topic_docs['language'].value_counts()
            
            composition = {
                'Topic': topic_id,
                'Total_Documents': total_docs,
                'Chinese_Count': lang_counts.get('zh', 0),
                'Russian_Count': lang_counts.get('ru', 0),
                'English_Count': lang_counts.get('en', 0),
                'Mixed_Count': lang_counts.get('mixed', 0),
                'Unknown_Count': lang_counts.get('unknown', 0),
            }
            
            # è®¡ç®—ç™¾åˆ†æ¯”
            composition.update({
                'Chinese_Percentage': (composition['Chinese_Count'] / total_docs) * 100,
                'Russian_Percentage': (composition['Russian_Count'] / total_docs) * 100,
                'English_Percentage': (composition['English_Count'] / total_docs) * 100,
                'Mixed_Percentage': (composition['Mixed_Count'] / total_docs) * 100,
                'Unknown_Percentage': (composition['Unknown_Count'] / total_docs) * 100,
            })
            
            # ä¸»è¦è¯­è¨€æ ‡ç­¾
            max_lang = max(lang_counts.items(), key=lambda x: x[1])
            composition['Dominant_Language'] = max_lang[0]
            composition['Dominance_Percentage'] = (max_lang[1] / total_docs) * 100
            
            # åˆ†ç±»ä¸»é¢˜ç±»å‹
            zh_pct = composition['Chinese_Percentage']
            ru_pct = composition['Russian_Percentage']
            en_pct = composition['English_Percentage']
            
            if zh_pct > 70:
                topic_type = 'Chinese-Dominant'
            elif ru_pct > 70:
                topic_type = 'Russian-Dominant'
            elif en_pct > 70:
                topic_type = 'English-Dominant'
            elif zh_pct + ru_pct > 80:
                topic_type = 'Sino-Russian'
            elif abs(zh_pct - ru_pct) < 20 and zh_pct + ru_pct > 50:
                topic_type = 'Balanced-Multilingual'
            else:
                topic_type = 'Other-Multilingual'
            
            composition['Topic_Type'] = topic_type
            composition_data.append(composition)
        
        composition_df = pd.DataFrame(composition_data)
        
        if not composition_df.empty:
            logger.info(f"  âœ“ åˆ†æäº† {len(composition_df)} ä¸ªä¸»é¢˜çš„è¯­è¨€æ„æˆ")
            
            # ç»Ÿè®¡ä¸»é¢˜ç±»å‹åˆ†å¸ƒ
            type_counts = composition_df['Topic_Type'].value_counts()
            logger.info("  âœ“ ä¸»é¢˜ç±»å‹åˆ†å¸ƒ:")
            for topic_type, count in type_counts.items():
                logger.info(f"    {topic_type}: {count} ä¸ªä¸»é¢˜")
        
        return composition_df
    
    def generate_language_distribution_chart(self,
                                           composition_df: pd.DataFrame,
                                           output_path: str = None) -> str:
        """
        ç”Ÿæˆè¯­è¨€åˆ†å¸ƒå¯è§†åŒ–å›¾è¡¨
        
        Args:
            composition_df: ä¸»é¢˜è¯­è¨€æ„æˆæ•°æ®
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        """
        if composition_df.empty:
            logger.warning("  âš  æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
            return ""
        
        logger.info("ğŸ“ˆ ç”Ÿæˆè¯­è¨€åˆ†å¸ƒå›¾è¡¨...")
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        plt.style.use('default')
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Cross-Lingual Topic Composition Analysis', fontsize=16, fontweight='bold')
        
        # 1. ä¸»é¢˜ç±»å‹åˆ†å¸ƒé¥¼å›¾
        type_counts = composition_df['Topic_Type'].value_counts()
        colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FF99CC', '#99CCFF']
        ax1.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', 
                colors=colors[:len(type_counts)], startangle=90)
        ax1.set_title('Topic Type Distribution', fontweight='bold')
        
        # 2. è¯­è¨€æ¯”ä¾‹å †å æ¡å½¢å›¾
        topics = composition_df['Topic'].tolist()
        zh_pct = composition_df['Chinese_Percentage'].tolist()
        ru_pct = composition_df['Russian_Percentage'].tolist()
        en_pct = composition_df['English_Percentage'].tolist()
        
        x = range(len(topics))
        ax2.bar(x, zh_pct, label='Chinese', color='#FF6B6B', alpha=0.8)
        ax2.bar(x, ru_pct, bottom=zh_pct, label='Russian', color='#4ECDC4', alpha=0.8)
        
        # è®¡ç®—è‹±æ–‡çš„åº•éƒ¨ä½ç½®
        en_bottom = [zh_pct[i] + ru_pct[i] for i in range(len(topics))]
        ax2.bar(x, en_pct, bottom=en_bottom, label='English', color='#45B7D1', alpha=0.8)
        
        ax2.set_xlabel('Topic ID')
        ax2.set_ylabel('Language Percentage (%)')
        ax2.set_title('Language Composition by Topic', fontweight='bold')
        ax2.legend()
        ax2.set_xticks(x[::max(1, len(x)//10)])  # æ˜¾ç¤ºéƒ¨åˆ†xè½´æ ‡ç­¾ä»¥é¿å…é‡å 
        ax2.set_xticklabels([f'T{topics[i]}' for i in range(0, len(topics), max(1, len(topics)//10))])
        
        # 3. ä¸»å¯¼è¯­è¨€åˆ†å¸ƒ
        dominant_langs = composition_df['Dominant_Language'].value_counts()
        lang_colors = {'zh': '#FF6B6B', 'ru': '#4ECDC4', 'en': '#45B7D1', 'mixed': '#96CEB4', 'unknown': '#DDA0DD'}
        colors_for_dominant = [lang_colors.get(lang, '#gray') for lang in dominant_langs.index]
        
        bars = ax3.bar(range(len(dominant_langs)), dominant_langs.values, color=colors_for_dominant, alpha=0.8)
        ax3.set_xlabel('Dominant Language')
        ax3.set_ylabel('Number of Topics')
        ax3.set_title('Dominant Language Distribution', fontweight='bold')
        ax3.set_xticks(range(len(dominant_langs)))
        lang_labels = {'zh': 'Chinese', 'ru': 'Russian', 'en': 'English', 'mixed': 'Mixed', 'unknown': 'Unknown'}
        ax3.set_xticklabels([lang_labels.get(lang, lang) for lang in dominant_langs.index])
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}', ha='center', va='bottom')
        
        # 4. è¯­è¨€å¹³è¡¡åº¦æ•£ç‚¹å›¾
        sino_russian_topics = composition_df[
            (composition_df['Chinese_Percentage'] > 10) & 
            (composition_df['Russian_Percentage'] > 10)
        ]
        
        if not sino_russian_topics.empty:
            scatter = ax4.scatter(sino_russian_topics['Chinese_Percentage'], 
                                sino_russian_topics['Russian_Percentage'],
                                c=sino_russian_topics['English_Percentage'], 
                                cmap='viridis', alpha=0.7, s=60)
            
            # æ·»åŠ å¯¹è§’çº¿è¡¨ç¤ºå¹³è¡¡ç‚¹
            max_val = max(sino_russian_topics['Chinese_Percentage'].max(), 
                         sino_russian_topics['Russian_Percentage'].max())
            ax4.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Balance Line')
            
            ax4.set_xlabel('Chinese Percentage (%)')
            ax4.set_ylabel('Russian Percentage (%)')
            ax4.set_title('Sino-Russian Topic Balance\n(Color = English %)', fontweight='bold')
            ax4.legend()
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(scatter, ax=ax4)
            cbar.set_label('English Percentage (%)')
        else:
            ax4.text(0.5, 0.5, 'No Sino-Russian\nTopics Found', 
                    ha='center', va='center', transform=ax4.transAxes, fontsize=12)
            ax4.set_title('Sino-Russian Topic Balance', fontweight='bold')
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        if output_path is None:
            output_path = Path(self.results_paths['output_dir']) / 'è·¨è¯­è¨€åˆ†æå›¾'
        else:
            output_path = Path(output_path)
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ä¸ºPNGå’ŒPDF
        png_path = output_path.with_suffix('.png')
        pdf_path = output_path.with_suffix('.pdf')
        
        plt.savefig(png_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.savefig(pdf_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        logger.info(f"  âœ“ è·¨è¯­è¨€åˆ†æå›¾è¡¨å·²ä¿å­˜: {png_path}")
        logger.info(f"  âœ“ PDFç‰ˆæœ¬å·²ä¿å­˜: {pdf_path}")
        
        return str(png_path)
    
    def save_language_composition_report(self,
                                       composition_df: pd.DataFrame,
                                       document_languages: List[str]) -> str:
        """
        ä¿å­˜è¯­è¨€æ„æˆæŠ¥å‘Š
        
        Args:
            composition_df: ä¸»é¢˜è¯­è¨€æ„æˆæ•°æ®
            document_languages: æ–‡æ¡£è¯­è¨€åˆ—è¡¨
        
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        output_path = Path(self.results_paths['cross_lingual_file'])
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            if not composition_df.empty:
                # æ·»åŠ æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
                total_stats = {
                    'Topic': 'OVERALL',
                    'Total_Documents': len(document_languages),
                    'Chinese_Count': document_languages.count('zh'),
                    'Russian_Count': document_languages.count('ru'),
                    'English_Count': document_languages.count('en'),
                    'Mixed_Count': document_languages.count('mixed'),
                    'Unknown_Count': document_languages.count('unknown'),
                }
                
                # è®¡ç®—æ€»ä½“ç™¾åˆ†æ¯”
                total = total_stats['Total_Documents']
                total_stats.update({
                    'Chinese_Percentage': (total_stats['Chinese_Count'] / total) * 100,
                    'Russian_Percentage': (total_stats['Russian_Count'] / total) * 100,
                    'English_Percentage': (total_stats['English_Count'] / total) * 100,
                    'Mixed_Percentage': (total_stats['Mixed_Count'] / total) * 100,
                    'Unknown_Percentage': (total_stats['Unknown_Count'] / total) * 100,
                    'Dominant_Language': max(
                        [('zh', total_stats['Chinese_Count']),
                         ('ru', total_stats['Russian_Count']),
                         ('en', total_stats['English_Count'])],
                        key=lambda x: x[1]
                    )[0],
                    'Topic_Type': 'Overall_Statistics'
                })
                
                # åˆå¹¶æ•°æ®
                final_df = pd.concat([
                    composition_df,
                    pd.DataFrame([total_stats])
                ], ignore_index=True)
                
                # ä¿å­˜CSV
                final_df.to_csv(output_path, index=False, encoding='utf-8-sig')
                logger.info(f"  âœ“ è·¨è¯­è¨€æ„æˆæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            
            return str(output_path)
            
        except Exception as e:
            logger.error(f"  âœ— ä¿å­˜è·¨è¯­è¨€æŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def run_full_cross_lingual_analysis(self,
                                       documents: List[str],
                                       topics: List[int]) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„è·¨è¯­è¨€åˆ†æ
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            topics: ä¸»é¢˜åˆ—è¡¨
            
        Returns:
            å®Œæ•´çš„è·¨è¯­è¨€åˆ†æç»“æœ
        """
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´è·¨è¯­è¨€ä¸»é¢˜æˆåˆ†åˆ†æ...")
        
        # 1. åˆ†ææ–‡æ¡£è¯­è¨€
        document_languages = self.analyze_document_languages(documents)
        
        # 2. åˆ†æä¸»é¢˜è¯­è¨€æ„æˆ
        composition_df = self.analyze_topic_language_composition(topics, document_languages)
        
        # 3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        chart_path = ""
        if not composition_df.empty:
            chart_path = self.generate_language_distribution_chart(composition_df)
        
        # 4. ä¿å­˜åˆ†ææŠ¥å‘Š
        report_path = self.save_language_composition_report(composition_df, document_languages)
        
        # 5. ç”Ÿæˆåˆ†ææ‘˜è¦
        summary = self._generate_analysis_summary(composition_df, document_languages)
        
        results = {
            'document_languages': document_languages,
            'composition_df': composition_df,
            'chart_path': chart_path,
            'report_path': report_path,
            'summary': summary
        }
        
        logger.info("âœ… è·¨è¯­è¨€ä¸»é¢˜æˆåˆ†åˆ†æå®Œæˆ")
        return results
    
    def _generate_analysis_summary(self,
                                  composition_df: pd.DataFrame,
                                  document_languages: List[str]) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        if composition_df.empty:
            return {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_docs = len(document_languages)
        total_topics = len(composition_df)
        
        # è¯­è¨€åˆ†å¸ƒ
        lang_dist = {
            'chinese': document_languages.count('zh'),
            'russian': document_languages.count('ru'),
            'english': document_languages.count('en'),
            'mixed': document_languages.count('mixed'),
            'unknown': document_languages.count('unknown')
        }
        
        # ä¸»é¢˜ç±»å‹åˆ†å¸ƒ
        topic_types = composition_df['Topic_Type'].value_counts().to_dict()
        
        # å…³é”®æ´å¯Ÿ
        insights = []
        
        # ä¸­ä¿„å…±é€šè®®é¢˜
        sino_russian_topics = composition_df[
            (composition_df['Chinese_Percentage'] > 20) & 
            (composition_df['Russian_Percentage'] > 20)
        ]
        insights.append(f"å‘ç° {len(sino_russian_topics)} ä¸ªä¸­ä¿„å…±é€šè®®é¢˜")
        
        # è¯­è¨€ä¸»å¯¼è®®é¢˜
        zh_dominant = len(composition_df[composition_df['Dominant_Language'] == 'zh'])
        ru_dominant = len(composition_df[composition_df['Dominant_Language'] == 'ru'])
        en_dominant = len(composition_df[composition_df['Dominant_Language'] == 'en'])
        
        insights.append(f"ä¸­æ–‡ä¸»å¯¼è®®é¢˜: {zh_dominant} ä¸ª")
        insights.append(f"ä¿„æ–‡ä¸»å¯¼è®®é¢˜: {ru_dominant} ä¸ª")
        insights.append(f"è‹±æ–‡ä¸»å¯¼è®®é¢˜: {en_dominant} ä¸ª")
        
        return {
            'total_documents': total_docs,
            'total_topics': total_topics,
            'language_distribution': lang_dist,
            'topic_type_distribution': topic_types,
            'key_insights': insights
        }
