"""
è°ƒå‚ç»“æœç®¡ç†å™¨
==============
ç®¡ç†è¶…å‚æ•°ä¼˜åŒ–çš„ç»“æœå’Œå€™é€‰å‚æ•°
"""

import yaml
import json
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class TuningManager:
    """è°ƒå‚ç»“æœç®¡ç†å™¨"""
    
    def __init__(self, config_path: str):
        """
        åˆå§‹åŒ–è°ƒå‚ç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = Path(config_path)
        self.results_dir = Path("results")
        self.results_dir.mkdir(exist_ok=True)
    
    def save_tuning_results(self, optimization_results: Dict[str, Any]) -> str:
        """
        ä¿å­˜è°ƒå‚ç»“æœå¹¶æ›´æ–°config.yaml
        
        Args:
            optimization_results: ä¼˜åŒ–ç»“æœ
            
        Returns:
            å€™é€‰å‚æ•°æ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸ’¾ ä¿å­˜è°ƒå‚ç»“æœ...")
        
        try:
            # 1. ç”Ÿæˆå€™é€‰å‚æ•°æ–‡ä»¶
            candidates_file = self._generate_candidates_file(optimization_results)
            
            # 2. æ›´æ–°config.yamlä¸­çš„å€™é€‰å‚æ•°
            self._update_config_candidates(optimization_results)
            
            logger.info("âœ… è°ƒå‚ç»“æœä¿å­˜å®Œæˆ")
            return candidates_file
            
        except Exception as e:
            logger.error(f"âŒ è°ƒå‚ç»“æœä¿å­˜å¤±è´¥: {e}")
            raise
    
    def _generate_candidates_file(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå€™é€‰å‚æ•°æ–‡ä»¶"""
        candidates_file = self.results_dir / 'å€™é€‰å‚æ•°.yaml'
        
        candidates_data = {
            'tuning_metadata': {
                'tuning_date': datetime.now().isoformat(),
                'n_trials': results.get('n_trials', 0),
                'best_score': results.get('best_score', 0),
                'optimization_time': results.get('optimization_time', 0)
            },
            'candidates': {}
        }
        
        # æ·»åŠ Top 5å€™é€‰
        top_params = results.get('top_parameters') or results.get('top_5_results') or []
        for i, item in enumerate(top_params[:5], 1):
            params = item.get('params', item) if isinstance(item, dict) else {}
            params = params if isinstance(params, dict) else {}
            raw_score = item.get('score') if isinstance(item, dict) else None
            score = raw_score if raw_score is not None else params.get('score')

            candidates_data['candidates'][f'candidate_{i}'] = {
                'min_topic_size': params.get('min_topic_size'),
                'n_neighbors': params.get('n_neighbors'),
                'n_components': params.get('n_components'),
                'min_cluster_size': params.get('min_cluster_size'),
                'min_samples': params.get('min_samples'),
                'quality_score': score,
                'rank': i
            }
        
        with open(candidates_file, 'w', encoding='utf-8') as f:
            yaml.dump(candidates_data, f, default_flow_style=False, allow_unicode=True, indent=2)
        
        logger.info(f"ğŸ“‹ å€™é€‰å‚æ•°æ–‡ä»¶å·²ç”Ÿæˆ: {candidates_file}")
        return str(candidates_file)
    
    def _update_config_candidates(self, results: Dict[str, Any]):
        """æ›´æ–°config.yamlä¸­çš„å€™é€‰å‚æ•°ï¼ˆKISSåŸåˆ™ï¼šä»manualè¯»å–å…¨éƒ¨é…ç½®ï¼Œåªæ›´æ–°å€™é€‰å‚æ•°ï¼‰"""
        try:
            # KISSæ–¹æ¡ˆï¼šä»config_manual.yamlè¯»å–å®Œæ•´é…ç½®ä½œä¸ºåŸºç¡€
            manual_config_path = self.config_path.parent / 'config_manual.yaml'
            if manual_config_path.exists():
                with open(manual_config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                logger.info("âœ“ ä»config_manual.yamlè¯»å–åŸºç¡€é…ç½®")
            else:
                # å¦‚æœmanualä¸å­˜åœ¨ï¼Œè¯»å–å½“å‰config
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                logger.warning("âš  config_manual.yamlä¸å­˜åœ¨ï¼Œä½¿ç”¨å½“å‰config.yaml")
            
            # ç¡®ä¿candidate_parameterséƒ¨åˆ†å­˜åœ¨
            if 'candidate_parameters' not in config:
                config['candidate_parameters'] = {}
            
            # åªæ›´æ–°å€™é€‰å‚æ•°éƒ¨åˆ†
            top_params = results.get('top_parameters') or results.get('top_5_results') or []
            for i, item in enumerate(top_params[:5], 1):
                params = item.get('params', item) if isinstance(item, dict) else {}
                params = params if isinstance(params, dict) else {}
                raw_score = item.get('score') if isinstance(item, dict) else None
                score = raw_score if raw_score is not None else params.get('score')

                config['candidate_parameters'][f'candidate_{i}'] = {
                    'min_topic_size': params.get('min_topic_size'),
                    'n_neighbors': params.get('n_neighbors'),
                    'n_components': params.get('n_components'),
                    'min_cluster_size': params.get('min_cluster_size'),
                    'min_samples': params.get('min_samples'),
                    'quality_score': score,
                    'rank': i
                }
            
            # åˆ›å»ºå¤‡ä»½
            backup_dir = self.results_dir / 'config_backups'
            backup_dir.mkdir(parents=True, exist_ok=True)
            backup_path = backup_dir / f'config_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.yaml'
            with open(backup_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
            
            # ä¿å­˜æ›´æ–°çš„é…ç½®åˆ°config.yaml
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
            
            logger.info("âœ… config.yamlå·²æ›´æ–°å€™é€‰å‚æ•°ï¼ˆæ‰€æœ‰ç”¨æˆ·é…ç½®å·²ä»manualä¿ç•™ï¼‰")
            logger.info(f"ğŸ“‹ é…ç½®å¤‡ä»½å·²ä¿å­˜: {backup_path}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°config.yamlå¤±è´¥: {e}")
    
    def _generate_selection_guide(self, results: Dict[str, Any]):
        """ç”Ÿæˆå€™é€‰å‚æ•°é€‰æ‹©æŒ‡å—"""
        guide_file = self.results_dir / 'å€™é€‰å‚æ•°é€‰æ‹©æŒ‡å—.txt'
        
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write("ğŸ¯ è°ƒå‚å®Œæˆï¼å€™é€‰å‚æ•°é€‰æ‹©æŒ‡å—\n")
            f.write("=" * 50 + "\n\n")

            f.write("ğŸ“Š æœºå™¨æ¨èçš„Top 5å‚æ•°ç»„åˆ:\n")
            f.write("-" * 30 + "\n")

            top_params = results.get('top_parameters') or results.get('top_5_results') or []
            for i, item in enumerate(top_params[:5], 1):
                params = item.get('params', item) if isinstance(item, dict) else {}
                params = params if isinstance(params, dict) else {}
                raw_score = item.get('score') if isinstance(item, dict) else None
                score = raw_score if raw_score is not None else params.get('score')

                if isinstance(score, (int, float)):
                    score_str = f"{float(score):.4f}"
                elif score is not None:
                    score_str = str(score)
                else:
                    score_str = "N/A"
                f.write(f"\nğŸ† å€™é€‰ {i} (ä¸€è‡´æ€§åˆ†æ•°: {score_str})\n")
                f.write(f"   å‚æ•°: ä¸»é¢˜å¤§å°{params.get('min_topic_size')}, ")
                f.write(f"é‚»å±…æ•°{params.get('n_neighbors')}, ")
                f.write(f"èšç±»å¤§å°{params.get('min_cluster_size')}\n")

                # é€‚ç”¨åœºæ™¯å»ºè®®
                if i == 1:
                    f.write("   ğŸ’¡ æ¨è: æ•°å­¦æŒ‡æ ‡æœ€ä¼˜ï¼Œé€šå¸¸æ˜¯æœ€ä½³èµ·ç‚¹\n")
                elif params.get('min_topic_size', 15) <= 10:
                    f.write("   ğŸ’¡ é€‚åˆ: éœ€è¦å‘ç°ç»†ç²’åº¦ä¸»é¢˜çš„ç ”ç©¶\n")
                elif params.get('min_topic_size', 15) >= 30:
                    f.write("   ğŸ’¡ é€‚åˆ: éœ€è¦å®è§‚ä¸»é¢˜æ¦‚è§ˆçš„ç ”ç©¶\n")
                else:
                    f.write("   ğŸ’¡ é€‚åˆ: å¹³è¡¡å‹ç ”ç©¶éœ€æ±‚\n")

            f.write("\n" + "ğŸ”„ ä¸‹ä¸€æ­¥æ“ä½œ:" + "\n")
            f.write("-" * 20 + "\n")
            f.write("1. åœ¨config.yamlä¸­è®¾ç½®: selected_candidate: 1 (é€‰æ‹©å€™é€‰1)\n")
            f.write("2. ä¿®æ”¹è¿è¡Œæ¨¡å¼: mode: 'analyze'\n")
            f.write("3. è¿è¡Œåˆ†æ: python main.py --run\n")
            f.write("4. æŸ¥çœ‹results/æ–‡ä»¶å¤¹ä¸­çš„åˆ†æç»“æœ\n")
            f.write("5. é‡å¤æ­¥éª¤1-4ï¼Œæµ‹è¯•å…¶ä»–å€™é€‰å‚æ•°\n")
            f.write("6. å¯¹æ¯”ä¸åŒå€™é€‰çš„ä¸»é¢˜è´¨é‡ï¼Œé€‰æ‹©æœ€ç¬¦åˆç ”ç©¶éœ€æ±‚çš„\n\n")

            f.write("ğŸ“ ä¸“å®¶å»ºè®®:\n")
            f.write("-" * 15 + "\n")
            f.write("â€¢ æ•°å­¦åˆ†æ•°é«˜ä¸ç­‰äºç ”ç©¶ä»·å€¼é«˜\n")
            f.write("â€¢ è¯·ç»“åˆæ‚¨çš„é¢†åŸŸçŸ¥è¯†åˆ¤æ–­ä¸»é¢˜æ˜¯å¦æœ‰æ„ä¹‰\n")
            f.write("â€¢ ç»†ç²’åº¦ä¸»é¢˜é€‚åˆæ·±åº¦åˆ†æï¼Œç²—ç²’åº¦é€‚åˆå®è§‚æ¦‚è§ˆ\n")
            f.write("â€¢ å»ºè®®æµ‹è¯•å‰3ä¸ªå€™é€‰ï¼Œå¯¹æ¯”ä¸»é¢˜å…³é”®è¯çš„è§£é‡ŠåŠ›\n")
            f.write("â€¢ æœ€ç»ˆé€‰æ‹©åº”æœåŠ¡äºæ‚¨çš„ç ”ç©¶é—®é¢˜å’Œè®ºæ–‡è®ºç‚¹\n")

        logger.info(f"ğŸ“‹ é€‰æ‹©æŒ‡å—å·²ç”Ÿæˆ: {guide_file}")


def save_tuning_results(config_path: str, optimization_results: Dict[str, Any]) -> str:
    """
    ä¾¿æ·å‡½æ•°ï¼šä¿å­˜è°ƒå‚ç»“æœ
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        optimization_results: ä¼˜åŒ–ç»“æœ
        
    Returns:
        å€™é€‰å‚æ•°æ–‡ä»¶è·¯å¾„
    """
    manager = TuningManager(config_path)
    return manager.save_tuning_results(optimization_results)
