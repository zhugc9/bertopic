#!/usr/bin/env python3
"""
BERTopicä¸»é¢˜åˆ†æç³»ç»Ÿ - ç»Ÿä¸€å…¥å£
===============================
é›†æˆè¶…å‚æ•°ä¼˜åŒ–ã€å¤šè¯­è¨€é¢„å¤„ç†ã€é«˜çº§å¯è§†åŒ–çš„å®Œæ•´åˆ†ææµç¨‹
"""

import sys
import yaml
import logging
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Any
from topic_analyzer.pipeline import AnalysisPipeline

def _ensure_utf8_output():
    """åœ¨Windowsæ§åˆ¶å°ç­‰ç¯å¢ƒä¸‹å°è¯•å¯ç”¨UTF-8è¾“å‡ºï¼Œé¿å…emojiå¯¼è‡´çš„ç¼–ç é”™è¯¯"""
    try:
        if hasattr(sys.stdout, "reconfigure"):
            sys.stdout.reconfigure(encoding="utf-8", errors="replace")
        if hasattr(sys.stderr, "reconfigure"):
            sys.stderr.reconfigure(encoding="utf-8", errors="replace")
    except Exception:
        pass

_ensure_utf8_output()

def run_analysis():
    """è¿è¡Œä¸»é¢˜åˆ†æ"""
    print("\n" + "="*60)
    print("å¼€å§‹BERTopicä¸»é¢˜åˆ†æ")
    print("="*60 + "\n")
    
    try:
        # å¯¼å…¥åˆ†ææ¨¡å—
        sys.path.append(str(Path(__file__).parent))
        from topic_analyzer.pipeline import AnalysisPipeline
        
        # åŠ è½½é…ç½® - ç›´æ¥åŠ è½½YAMLæ–‡ä»¶
        config_path = Path(__file__).parent / "config.yaml"
        from config_loader import load_runtime_config
        runtime_config = load_runtime_config(config_path)
        pipeline = AnalysisPipeline(config_path, runtime_config)
        
        print("ğŸ“ åŠ è½½æ•°æ®...")
        result = pipeline.run_analysis()
        print(f"âœ… å·²åŠ è½½ {len(result.documents)} æ¡æ–‡æ¡£")

        # ç”Ÿæˆç»“æœ
        print("ğŸ“Š ç”Ÿæˆåˆ†æç»“æœ...")
        pipeline.generate_results(result)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨SOTAå¯è§†åŒ–
        sota_config = pipeline.runtime_config.get('visualization', {}).get('sota_charts', {})
        if sota_config.get('enable', True):
            print("ğŸ¨ ç”ŸæˆSOTAçº§å¯è§†åŒ–...")
            sota_charts = pipeline.topic_analyzer.generate_sota_visualizations(
                result.topic_model, result.documents, result.topics, result.metadata_df
            )
            if sota_charts:
                print(f"âœ… ç”ŸæˆSOTAå›¾è¡¨: {len(sota_charts)} ä¸ª")
        
        # åŸºç¡€ç»Ÿè®¡
        topic_info = result.topic_model.get_topic_info()
        n_topics = len(topic_info) - 1  # -1æ’é™¤å™ªå£°ä¸»é¢˜
        
        print(f"\nåˆ†æå®Œæˆ")
        print(f"ç»“æœä¿å­˜åœ¨: {Path(pipeline.runtime_config['results_paths']['output_dir'])}")
        print(f"å‘ç°ä¸»é¢˜æ•°: {n_topics}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        logging.error(f"Analysis failed: {e}")
        return False


def run_user_friendly_analysis() -> bool:
    """
    è¿è¡Œç”¨æˆ·å‹å¥½çš„åˆ†æï¼ˆåŸºäºconfig.yamlç”¨æˆ·é…ç½®ï¼‰
    """
    try:
        config_path = Path(__file__).parent / "config.yaml"
        
        from config_loader import load_runtime_config
        runtime_config = load_runtime_config(config_path)
        analysis_mode = runtime_config.get('analysis', {}).get('mode', 'analyze')
        
        print(f"\nğŸ¯ æ£€æµ‹åˆ°è¿è¡Œæ¨¡å¼: {analysis_mode}")
        
        if analysis_mode == 'tune':
            return run_tuning_phase(runtime_config, config_path)
        else:
            return run_analysis_phase(runtime_config, config_path)
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_tuning_phase(runtime_config: Dict[str, Any], config_path: Path) -> bool:
    """
    è¿è¡Œç¬¬ä¸€é˜¶æ®µï¼šæœºå™¨è°ƒå‚
    
    Args:
        translator: é…ç½®ç¿»è¯‘å™¨
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print("\nç¬¬ä¸€é˜¶æ®µï¼šè‡ªåŠ¨è°ƒå‚")
    print("=" * 50)
    
    try:
        pipeline = AnalysisPipeline(config_path, runtime_config)
        optimization_results = pipeline.run_hyperparameter_search()
        if optimization_results:
            from tools.tuning_manager import save_tuning_results
            save_tuning_results(str(config_path), optimization_results)
            success = True
        else:
            success = False
        
        if success:
            print("\nç¬¬ä¸€é˜¶æ®µè°ƒå‚å®Œæˆ")
            print("\nä¸‹ä¸€æ­¥æ“ä½œï¼š")
            print("1. æŸ¥çœ‹ results/å€™é€‰å‚æ•°é€‰æ‹©æŒ‡å—.txt")
            print("2. åœ¨config.yamlä¸­è®¾ç½® selected_candidate: X (1-5)")
            print("3. å°† mode æ”¹ä¸º 'analyze' å¹¶é‡æ–°è¿è¡Œ")
        else:
            print("\nâŒ è°ƒå‚å¤±è´¥")
            
        return success
        
    except Exception as e:
        print(f"\nâŒ è°ƒå‚é˜¶æ®µå¤±è´¥: {e}")
        return False


def run_analysis_phase(runtime_config: Dict[str, Any], config_path: Path) -> bool:
    """
    è¿è¡Œç¬¬äºŒé˜¶æ®µï¼šæ­£å¼åˆ†æ
    
    Args:
        translator: é…ç½®ç¿»è¯‘å™¨
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print("\nğŸ“Š ç¬¬äºŒé˜¶æ®µï¼šæ­£å¼åˆ†æ (æ·±åº¦æ¨¡å¼)")
    print("=" * 50)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰å‚æ•°
    candidate_config = runtime_config.get('candidate_parameters', {})
    selected_candidate = candidate_config.get('selected_candidate', 1)
    candidate_key = f'candidate_{selected_candidate}'
    candidate = candidate_config.get(candidate_key)
    
    if candidate:
        print(f"ğŸ¯ ä½¿ç”¨å€™é€‰å‚æ•° {selected_candidate}")
        print(f"ğŸ“‹ å‚æ•°ç‰¹å¾: {candidate.get('description', 'æœªçŸ¥')}")
        print(f"ğŸ“ˆ è´¨é‡åˆ†æ•°: {candidate.get('quality_score', 'N/A')}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°å€™é€‰å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    # åº”ç”¨å€™é€‰å‚æ•°è¦†ç›–è¿è¡Œæ—¶é…ç½®
    if candidate:
        bertopic_params = runtime_config.setdefault('bertopic_params', {})
        umap_params = bertopic_params.setdefault('umap_params', {})
        hdbscan_params = bertopic_params.setdefault('hdbscan_params', {})

        umap_keys = ['n_neighbors', 'n_components', 'min_dist', 'metric']
        for key in umap_keys:
            if key in candidate and candidate[key] is not None:
                umap_params[key] = candidate[key]

        hdbscan_keys = ['min_cluster_size', 'min_samples', 'cluster_selection_method']
        for key in hdbscan_keys:
            if key in candidate and candidate[key] is not None:
                hdbscan_params[key] = candidate[key]

        if 'min_topic_size' in candidate and candidate['min_topic_size'] is not None:
            bertopic_params['min_topic_size'] = candidate['min_topic_size']
    
    try:
        # è½¬æ¢æŠ€æœ¯é…ç½®
        pipeline = AnalysisPipeline(config_path, runtime_config)
        result = pipeline.run_analysis()
        pipeline.generate_results(result)
        success = True
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨SOTAå¯è§†åŒ–
        sota_config = pipeline.runtime_config.get('visualization', {}).get('sota_charts', {})
        if sota_config.get('enable', True):
            print("ğŸ¨ ç”ŸæˆSOTAçº§å¯è§†åŒ–...")
            try:
                sota_charts = pipeline.topic_analyzer.generate_sota_visualizations(
                    result.topic_model, result.documents, result.topics, result.metadata_df
                )
                if sota_charts:
                    print(f"âœ… ç”ŸæˆSOTAå›¾è¡¨: {len(sota_charts)} ä¸ª")
            except Exception as e:
                print(f"âš  SOTAå¯è§†åŒ–ç”Ÿæˆæ—¶é‡åˆ°é—®é¢˜: {e}")
        
        if success:
            print(f"\nç¬¬äºŒé˜¶æ®µåˆ†æå®Œæˆ")
            results_dir = Path(runtime_config['results_paths']['output_dir'])
            print(f"ç»“æœä¿å­˜åœ¨: {results_dir}")
            generate_analysis_summary(results_dir, runtime_config, selected_candidate)
        else:
            print(f"\nâŒ åˆ†æå¤±è´¥")
            
        return success
        
    except Exception as e:
        import traceback
        print(f"\nâŒ åˆ†æé˜¶æ®µå¤±è´¥: {e}")
        print(f"\nè¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š")
        traceback.print_exc()
        return False


def generate_user_summary(results_dir: Path, mode: str, user_config: dict):
    """
    ç”Ÿæˆç”¨æˆ·å‹å¥½çš„ç»“æœæ‘˜è¦
    
    Args:
        results_dir: ç»“æœç›®å½•
        mode: åˆ†ææ¨¡å¼
        user_config: ç”¨æˆ·é…ç½®
    """
    try:
        summary_file = results_dir / 'analysis_summary_for_user.txt'
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ğŸ“ BERTopicä¸»é¢˜åˆ†æç»“æœæ‘˜è¦\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"ğŸ“Š åˆ†ææ¨¡å¼: {mode}\n")
            f.write(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            
            # æ•°æ®ä¿¡æ¯
            data_paths = user_config.get('data_paths', {})
            f.write("ğŸ“ åˆ†ææ•°æ®:\n")
            if data_paths.get('media_data'):
                f.write(f"  - ä¼ ç»Ÿåª’ä½“æ•°æ®: {data_paths['media_data']}\n")
            if data_paths.get('social_media_data'):
                f.write(f"  - ç¤¾äº¤åª’ä½“æ•°æ®: {data_paths['social_media_data']}\n")
            f.write("\n")
            
            # åˆ†æè®¾ç½®
            topic_config = user_config.get('topic_settings', {})
            f.write("âš™ï¸ åˆ†æè®¾ç½®:\n")
            f.write(f"  - ä¸»é¢˜æ•°é‡: {topic_config.get('expected_topics', 'auto')}\n")
            f.write(f"  - æœ€å°ä¸»é¢˜å¤§å°: {topic_config.get('min_documents_per_topic', 15)}\n")
            f.write(f"  - å…³é”®è¯ç²¾åº¦: {topic_config.get('advanced', {}).get('ngram_range', [1, 3])}\n")
            f.write(f"  - è¯­è¨€æ¨¡å¼: {topic_config.get('text_language', 'multilingual')}\n\n")
            
            # åŠŸèƒ½å¯ç”¨çŠ¶æ€
            features = user_config.get('features', {})
            auto_tuning_cfg = user_config.get('hyperparameter_optimization', {})
            viz_config = user_config.get('visualization', {})
            f.write("ğŸ”§ åŠŸèƒ½å¯ç”¨çŠ¶æ€:\n")
            f.write(f"  - è¶…å‚æ•°ä¼˜åŒ–: {'âœ“' if auto_tuning_cfg.get('enable') else 'âœ—'}\n")
            f.write(f"  - å­¦æœ¯çº§å¯è§†åŒ–: {'âœ“' if viz_config.get('sota_charts', {}).get('enable', True) else 'âœ—'}\n")
            f.write(f"  - æ—¶é—´åˆ†æ: {'âœ“' if features.get('time_evolution', {}).get('enable') else 'âœ—'}\n")
            f.write(f"  - æ¥æºåˆ†æ: {'âœ“' if features.get('source_comparison', {}).get('enable') else 'âœ—'}\n")
            f.write(f"  - æ¡†æ¶åˆ†æ: {'âœ“' if features.get('frame_analysis', {}).get('enable') else 'âœ—'}\n\n")
            
            # ç»“æœæ–‡ä»¶
            f.write("ğŸ“„ ä¸»è¦ç»“æœæ–‡ä»¶:\n")
            f.write("  - ä¸»é¢˜æ‘˜è¦è¡¨.csv: ä¸»é¢˜å…³é”®è¯å’Œç»Ÿè®¡ä¿¡æ¯\n")
            f.write("  - æ–‡æ¡£ä¸»é¢˜åˆ†å¸ƒè¡¨.csv: æ–‡æ¡£ä¸ä¸»é¢˜çš„å¯¹åº”å…³ç³»\n")
            f.write("  - å›¾è¡¨æ–‡ä»¶å¤¹: åŒ…å«æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨\n\n")
            
            # ä½¿ç”¨å»ºè®®
            f.write("ğŸ’¡ ç»“æœä½¿ç”¨å»ºè®®:\n")
            f.write("  1. æŸ¥çœ‹ ä¸»é¢˜æ‘˜è¦è¡¨.csv äº†è§£å‘ç°çš„ä¸»é¢˜\n")
            f.write("  2. æŸ¥çœ‹å›¾è¡¨æ–‡ä»¶å¤¹ä¸­çš„å¯è§†åŒ–ç»“æœ\n")
            f.write("  3. å¦‚éœ€è°ƒæ•´ï¼Œä¿®æ”¹ config.yaml ä¸­çš„å‚æ•°é‡æ–°è¿è¡Œ\n")
            f.write("  4. è®ºæ–‡å†™ä½œå¯ç›´æ¥ä½¿ç”¨ç”Ÿæˆçš„é«˜è´¨é‡å›¾è¡¨\n\n")
            
            f.write("=" * 60 + "\n")
            f.write("åˆ†æå®Œæˆã€‚å¦‚æœ‰é—®é¢˜è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ã€‚\n")
            f.write("=" * 60 + "\n")
        
        print(f"ğŸ“‹ ç”¨æˆ·æ‘˜è¦å·²ç”Ÿæˆ: {summary_file}")
        
    except Exception as e:
        print(f"âš ï¸ ç”¨æˆ·æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")


def generate_analysis_summary(results_dir: Path, user_config: dict, candidate_num: int):
    """
    ç”Ÿæˆåˆ†æé˜¶æ®µçš„ç»“æœæ‘˜è¦
    
    Args:
        results_dir: ç»“æœç›®å½•
        user_config: ç”¨æˆ·é…ç½®
        candidate_num: å€™é€‰å‚æ•°ç¼–å·
    """
    try:
        summary_file = results_dir / f'5-å€™é€‰{candidate_num}_åˆ†ææ‘˜è¦.txt'
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write(f"ğŸ“ å€™é€‰å‚æ•° {candidate_num} åˆ†æç»“æœæ‘˜è¦\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"ğŸ¯ ä½¿ç”¨å€™é€‰: ç¬¬ {candidate_num} ç»„å‚æ•°\n\n")
            
            # å€™é€‰å‚æ•°ä¿¡æ¯
            candidate_config = user_config.get('candidate_parameters', {})
            if f'candidate_{candidate_num}' in candidate_config:
                candidate = candidate_config[f'candidate_{candidate_num}']
                f.write("ğŸ“Š å‚æ•°ä¿¡æ¯:\n")
                f.write(f"  - è´¨é‡åˆ†æ•°: {candidate.get('quality_score', 'N/A')}\n")
                f.write(f"  - å‚æ•°ç‰¹å¾: {candidate.get('description', 'æœªçŸ¥')}\n")
                f.write(f"  - æœ€å°ä¸»é¢˜å¤§å°: {candidate.get('min_topic_size', 'N/A')}\n")
                f.write(f"  - UMAPé‚»å±…æ•°: {candidate.get('n_neighbors', 'N/A')}\n")
                f.write(f"  - èšç±»å¤§å°: {candidate.get('min_cluster_size', 'N/A')}\n\n")
            
            # æ•°æ®ä¿¡æ¯
            data_paths = user_config.get('data_paths', {})
            f.write("ğŸ“ åˆ†ææ•°æ®:\n")
            if data_paths.get('media_data'):
                f.write(f"  - ä¼ ç»Ÿåª’ä½“æ•°æ®: {data_paths['media_data']}\n")
            if data_paths.get('social_media_data'):
                f.write(f"  - ç¤¾äº¤åª’ä½“æ•°æ®: {data_paths['social_media_data']}\n")
            f.write("\n")
            
            # ç»“æœæ–‡ä»¶
            f.write("ğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:\n")
            f.write("  - ä¸»é¢˜å…³é”®è¯è¡¨.csv: å‘ç°çš„ä¸»é¢˜åŠå…³é”®è¯\n")
            f.write("  - æ–‡æ¡£ä¸»é¢˜æ˜ å°„è¡¨.csv: æ¯ä¸ªæ–‡æ¡£çš„ä¸»é¢˜å½’å±\n")
            f.write("  - å›¾è¡¨æ–‡ä»¶: è®ºæ–‡çº§å¯è§†åŒ–å›¾è¡¨\n")
            f.write("  - åˆ†ææŠ¥å‘Š: è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯\n\n")
            
            f.write("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:\n")
            f.write("  1. æŸ¥çœ‹ä¸»é¢˜å…³é”®è¯è¡¨ï¼Œè¯„ä¼°ä¸»é¢˜è´¨é‡\n")
            f.write("  2. æ£€æŸ¥å›¾è¡¨æ–‡ä»¶ï¼Œç¡®è®¤å¯è§†åŒ–æ•ˆæœ\n")
            f.write("  3. å¦‚éœ€å¯¹æ¯”ï¼Œå¯é€‰æ‹©å…¶ä»–å€™é€‰å‚æ•°é‡æ–°åˆ†æ\n")
            f.write("  4. é€‰å®šæœ€ä½³å‚æ•°åï¼Œå¯ç”¨äºè®ºæ–‡å†™ä½œ\n\n")
            
            f.write("=" * 60 + "\n")
            f.write(f"ğŸ‰ å€™é€‰ {candidate_num} åˆ†æå®Œæˆï¼\n")
            f.write("=" * 60 + "\n")
        
        print(f"ğŸ“‹ åˆ†ææ‘˜è¦å·²ç”Ÿæˆ: {summary_file}")
        
    except Exception as e:
        print(f"âš ï¸ åˆ†ææ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")


def run_advanced_analysis(mode: str = 'standard') -> bool:
    """
    è¿è¡Œé«˜çº§åˆ†æï¼ˆå‘åå…¼å®¹ï¼‰
    
    Args:
        mode: åˆ†ææ¨¡å¼ (quick/standard/research)
    """
    # ä¸ºå‘åå…¼å®¹ä¿ç•™æ­¤å‡½æ•°ï¼Œä½†å»ºè®®ä½¿ç”¨ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    return run_user_friendly_analysis()


def create_cli_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="BERTopicä¸»é¢˜åˆ†æç³»ç»Ÿ - åšå£«ç”Ÿå‹å¥½ç‰ˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ“ ä½¿ç”¨è¯´æ˜ï¼ˆä¸“ä¸ºè®¡ç®—ä¼ æ’­å­¦åšå£«ç”Ÿè®¾è®¡ï¼‰:
  
  python main.py                    # äº¤äº’å¼ç•Œé¢ï¼ˆæ¨èï¼‰
  python main.py --run              # ç›´æ¥è¿è¡Œåˆ†æï¼ˆè¯»å–config.yamlï¼‰
  python tools/check_deps.py        # æ£€æŸ¥ç¯å¢ƒä¾èµ–ï¼ˆä»…è¯Šæ–­æ—¶ä½¿ç”¨ï¼‰
  
ğŸ’¡ æ‰€æœ‰åˆ†æå‚æ•°éƒ½åœ¨ config.yaml æ–‡ä»¶ä¸­è®¾ç½®ï¼š
  - æ•°æ®æ–‡ä»¶è·¯å¾„
  - åˆ†ææ¨¡å¼é€‰æ‹©  
  - ä¸»é¢˜æ•°é‡å’Œç²¾åº¦
  - å¯è§†åŒ–è®¾ç½®
  
ğŸ“ è®ºæ–‡å†™ä½œæµç¨‹ï¼š
  1. ä¿®æ”¹ config.yaml è®¾ç½®å‚æ•°
  2. è¿è¡Œ python main.py --run
  3. æŸ¥çœ‹ results/ æ–‡ä»¶å¤¹è·å–ç»“æœ
  4. ä½¿ç”¨ç”Ÿæˆçš„é«˜è´¨é‡å›¾è¡¨å†™è®ºæ–‡
        """
    )
    
    parser.add_argument(
        '--run', '-r',
        action='store_true',
        help='ç›´æ¥è¿è¡Œåˆ†æï¼ˆè¯»å–config.yamlé…ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--config',
        type=str,
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)'
    )
    
    return parser


if __name__ == "__main__":
    try:
        parser = create_cli_parser()
        args = parser.parse_args()
        
        # æ£€æŸ¥å‚æ•°
        if args.run:
            # ç›´æ¥è¿è¡Œåˆ†æ
            print("ğŸ¯ ç›´æ¥è¿è¡Œæ¨¡å¼ï¼šè¯»å– config.yaml é…ç½®...")
            success = run_user_friendly_analysis()
            try:
                input("\næŒ‰ä»»æ„é”®é€€å‡º...")
            except EOFError:
                pass
            sys.exit(0 if success else 1)
            
        else:
            # æ˜¾ç¤ºå¸®åŠ©
            parser.print_help()
            sys.exit(0)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­è¿è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)